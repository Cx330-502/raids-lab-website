diff --git crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.ko.md crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.ko.md
index 5eef193..61f978b 100644
--- crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.ko.md
+++ crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.ko.md
@@ -1,6 +1,6 @@
 ---
 title: DeepSeek R1 분산 추론의 빠른 배포
-description: 본 플랫폼은 DeepSeek R1 분산 추론을 빠르게 배포할 수 있는 작업 템플릿을 제공합니다. 이를 사용하여 분산 작업을 직접 생성하여 자신만의 DeepSeek를 빠르게 배포할 수 있으며, 웹 UI 인터페이스를 시작하여 대형 모델과 상호작용할 수도 있습니다.
+description: 본 플랫폼은 DeepSeek R1 분산 추론을 빠르게 배포할 수 있는 작업 템플릿을 제공합니다. 이를 사용하여 분산 작업을 직접 생성하여 자신만의 DeepSeek 를 빠르게 배포할 수 있으며, 웹 UI 인터페이스를 시작하여 대형 모델과 상호작용할 수도 있습니다.
 ---
 
 # DeepSeek R1 분산 추론의 빠른 배포
@@ -40,17 +40,17 @@ NCCL_DEBUG=TRACE python3 -m vllm.entrypoints.openai.api_server \
 
 ### 일반적인 문제점
 
-> 문제 1: ValueError: Bfloat16은 최소한 8.0 이상의 컴퓨팅 능력을 갖는 GPU에서만 지원됩니다. 사용 중인 Tesla V100-SXM2-32GB GPU의 컴퓨팅 능력은 7.0입니다. CLI에서 dtype 플래그를 명시적으로 설정하여 float16을 대신 사용할 수 있습니다. 예: --dtype=half.
+> 문제 1: ValueError: Bfloat16 은 최소한 8.0 이상의 컴퓨팅 능력을 갖는 GPU 에서만 지원됩니다. 사용 중인 Tesla V100-SXM2-32GB GPU 의 컴퓨팅 능력은 7.0 입니다. CLI 에서 dtype 플래그를 명시적으로 설정하여 float16 을 대신 사용할 수 있습니다. 예: --dtype=half.
 
-답변 1: vLLM 시작 파라미터에 --dtype=half를 추가합니다. 이 문제는 많은 가속 연산자들이 V100에서 실행되지 않는다는 불가피한 상황에서 비롯되며, 현재 많은 고성능 연산자들이 특정 하드웨어 제한을 가지고 있습니다.
+답변 1: vLLM 시작 파라미터에 --dtype=half 를 추가합니다. 이 문제는 많은 가속 연산자들이 V100 에서 실행되지 않는다는 불가피한 상황에서 비롯되며, 현재 많은 고성능 연산자들이 특정 하드웨어 제한을 가지고 있습니다.
 
 > 문제 2: 얼마나 많은 컴퓨팅 파워를 신청해야 할까요?
 
-답변 2: 메모리 사용량(최소) >= 모델 파라미터 수 * 배포 비트(bit) / 8. 예를 들어, 인스턴스에서 사용하는 32b 모델을 16bit로 배포한다면 최소 64GB의 메모리가 필요합니다. Crater의 한 장의 V100 메모리 용량은 32GB이므로 실제로 3~4장의 V100이 실행될 수 있으며, 이는 테스트를 위해 다중 머신을 사용하기 위해 8장의 카드를 사용했습니다.
+답변 2: 메모리 사용량 (최소) >= 모델 파라미터 수 * 배포 비트 (bit) / 8. 예를 들어, 인스턴스에서 사용하는 32b 모델을 16bit 로 배포한다면 최소 64GB 의 메모리가 필요합니다. Crater 의 한 장의 V100 메모리 용량은 32GB 이므로 실제로 3~4 장의 V100 이 실행될 수 있으며, 이는 테스트를 위해 다중 머신을 사용하기 위해 8 장의 카드를 사용했습니다.
 
-> 문제 3: sglang을 사용할 수 있나요?
+> 문제 3: sglang 을 사용할 수 있나요?
 
-답변 3: sglang 프레임워크는 7.0의 그래픽 카드를 사용하여 배포하는 것을 지원하지 않습니다. 또한 vllm은 V100에서 사용하는 것이 제한적입니다(정확히 어떤 기능들이 있는지는 직접 vllm의 문서와 issue 섹션을 참고하시기 바랍니다).
+답변 3: sglang 프레임워크는 7.0 의 그래픽 카드를 사용하여 배포하는 것을 지원하지 않습니다. 또한 vllm 은 V100 에서 사용하는 것이 제한적입니다 (정확히 어떤 기능들이 있는지는 직접 vllm 의 문서와 issue 섹션을 참고하시기 바랍니다).
 
 이제부터 DeepSeek R1 32b 모델을 작업 템플릿을 사용하여 빠르게 배포하여 대화를 시작할 수 있습니다! 🥳!
 
@@ -68,11 +68,11 @@ NCCL_DEBUG=TRACE python3 -m vllm.entrypoints.openai.api_server \
 
 Crater 플랫폼에서 **DeepSeek R1 분산 추론** 작업 템플릿을 사용하여 대형 모델 추론 서비스를 시작한 후, 환경 변수의 첫 번째 줄을 수정하여 OpenAI 서비스의 주소를 입력해야 합니다:
 
-다중 머신으로 모델을 배포하는 경우, 해당 작업의 「기본 정보」 섹션에서 **Ray Head 노드의 「내부 IP」**를 참조합니다.
+다중 머신으로 모델을 배포하는 경우, 해당 작업의「기본 정보」섹션에서 **Ray Head 노드의「내부 IP」**를 참조합니다.
 
 ![](./img/dis-deepseek-32b/dis-ip.webp)
 
-Open WebUI가 성공적으로 시작되면, 상세 페이지로 이동하여 「외부 액세스」를 클릭합니다. 우리는 이미 전달을 설정해 놓았으므로 클릭만 하면 액세스할 수 있습니다.
+Open WebUI 가 성공적으로 시작되면, 상세 페이지로 이동하여「외부 액세스」를 클릭합니다. 우리는 이미 전달을 설정해 놓았으므로 클릭만 하면 액세스할 수 있습니다.
 
 ![](./img/dis-deepseek-32b/openweb-fw.webp)
 
