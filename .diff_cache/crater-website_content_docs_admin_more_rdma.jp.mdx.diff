diff --git crater-website/content/docs/admin/more/rdma.jp.mdx crater-website/content/docs/admin/more/rdma.jp.mdx
index feb5d65..42d1a56 100644
--- crater-website/content/docs/admin/more/rdma.jp.mdx
+++ crater-website/content/docs/admin/more/rdma.jp.mdx
@@ -1,5 +1,5 @@
 ---
-title: "RDMAサポート"
+title: "RDMA サポート"
 description: "RDMA"
 ---
 
@@ -7,18 +7,18 @@ description: "RDMA"
 > - [Running tightly coupled HPC/AI workloads with InfiniBand using NVIDIA Network Operator on AKS \| Microsoft Community Hub](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/running-tightly-coupled-hpcai-workloads-with-infiniband-using-nvidia-network-ope/4117209)
 > - [Basic Knowledge and Differences of RoCE, IB, and TCP Networks](https://support.huawei.com/enterprise/en/doc/EDOC1100203339)
 
-正式に開始する前に、RDMAに関連する基礎知識を補足しておきます：
+正式に開始する前に、RDMA に関連する基礎知識を補足しておきます：
 
-- **RDMA**：これは、オペレーティングシステムのカーネルを迂回するネットワーク通信技術であり、その核心はネットワークカードを介してリモートメモリに直接アクセスすることにあり、従来のTCP/IPプロトコルスタックのデータコピーおよびコンテキストスイッチのオーバーヘッドを回避します。
-- **NVIDIA GPU Direct**[^2]：GPUのビデオメモリとネットワークカードのDMAエンジンを直接接続して実現します。GPUがリモートノードと通信する必要がある場合、データはInfiniBandまたはRoCEネットワークカードを介して直接転送され、ホストメモリを経由することなくなります。
-- **ネットワーク仮想化**：MacvlanとSR-IOVは2つの一般的なネットワーク仮想化のソリューションです。Macvlanは、コンテナに仮想ネットワークインターフェースを作成して、物理ネットワーク上では独立したデバイスとして表示させます。SR-IOVは、物理ネットワークカードのハードウェア仮想化能力を用いて、単一の物理機能（PF）を複数の仮想機能（VF）に分割し、それぞれのVFがPodに直接割り当てられることを可能にします。
-- **技術パス**：現在のRDMAには主にInfiniBandとRoCEの2つの実装方法があります[^6]。InfiniBandは原生的にRDMAプロトコルをサポートしており、専用のスイッチおよびサブネットマネージャーが必要で、独立ネットワークを構築するためコストが高くなります。RoCEv2は、従来のイーサネットインフラストラクチャを基盤としており、PFCやECNなどのフローコントロールメカニズムを用いてノンロス伝送を保証し、インターネット企業で広く使用されています。
+- **RDMA**：これは、オペレーティングシステムのカーネルを迂回するネットワーク通信技術であり、その核心はネットワークカードを介してリモートメモリに直接アクセスすることにあり、従来の TCP/IP プロトコルスタックのデータコピーおよびコンテキストスイッチのオーバーヘッドを回避します。
+- **NVIDIA GPU Direct**[^2]：GPU のビデオメモリとネットワークカードの DMA エンジンを直接接続して実現します。GPU がリモートノードと通信する必要がある場合、データは InfiniBand または RoCE ネットワークカードを介して直接転送され、ホストメモリを経由することなくなります。
+- **ネットワーク仮想化**：Macvlan と SR-IOV は 2 つの一般的なネットワーク仮想化のソリューションです。Macvlan は、コンテナに仮想ネットワークインターフェースを作成して、物理ネットワーク上では独立したデバイスとして表示させます。SR-IOV は、物理ネットワークカードのハードウェア仮想化能力を用いて、単一の物理機能（PF）を複数の仮想機能（VF）に分割し、それぞれの VF が Pod に直接割り当てられることを可能にします。
+- **技術パス**：現在の RDMA には主に InfiniBand と RoCE の 2 つの実装方法があります[^6]。InfiniBand は原生的に RDMA プロトコルをサポートしており、専用のスイッチおよびサブネットマネージャーが必要で、独立ネットワークを構築するためコストが高くなります。RoCEv2 は、従来のイーサネットインフラストラクチャを基盤としており、PFC や ECN などのフローコントロールメカニズムを用いてノンロス伝送を保証し、インターネット企業で広く使用されています。
 
-我々の研究室ではInfiniBandの方案を採用しています。そのため、まず関連機器のIB情報を確認します：
+我々の研究室では InfiniBand の方案を採用しています。そのため、まず関連機器の IB 情報を確認します：
 
-### 1. 単一ノードでInfiniBand関連情報をテストする
+### 1. 単一ノードで InfiniBand 関連情報をテストする
 
-まずホストマシンでテストを行います。クラウドに上げる前には、これらの機械のIBはすべて通っています：
+まずホストマシンでテストを行います。クラウドに上げる前には、これらの機械の IB はすべて通っています：
 
 ```bash
 $ ibdev2netdev
@@ -34,10 +34,10 @@ CA 'mlx5_1'
                 Link layer: InfiniBand
 ```
 
-- **Up**: このInfiniBandポートが正常にアクティブ化されてネットワークに接続されていることを示します。
-- **Down**: このInfiniBandポートがアクティブ化されていないか、ネットワーク接続が確立されていないことを示します。
+- **Up**: この InfiniBand ポートが正常にアクティブ化されてネットワークに接続されていることを示します。
+- **Down**: この InfiniBand ポートがアクティブ化されていないか、ネットワーク接続が確立されていないことを示します。
 
-### 2. Ansibleを使用してノードのネットワークインターフェースを一括で確認する
+### 2. Ansible を使用してノードのネットワークインターフェースを一括で確認する
 
 グループを定義します：
 
@@ -53,36 +53,36 @@ xx.xx.xx.[xx:xx]
 
 ```yaml
 ---
-- name: InfiniBandホストでibdev2netdevを実行
+- name: InfiniBand ホストで ibdev2netdev を実行
   hosts: ib-v100,ib-a100
   gather_facts: no
 
   tasks:
-    - name: ibdev2netdevコマンドを実行
+    - name: ibdev2netdev コマンドを実行
       ansible.builtin.command: ibdev2netdev
       register: ibdev_output
       changed_when: false
 
-    - name: ibdev2netdevの出力を表示
+    - name: ibdev2netdev の出力を表示
       ansible.builtin.debug:
         var: ibdev_output.stdout_lines
 ```
 
-返り値が長いため、ここでは全文を掲載しません。`ibdev2netdev`の出力結果から、クラスターの2種類のノードのInfiniBand構成が異なっていることがわかります：
+返り値が長いため、ここでは全文を掲載しません。`ibdev2netdev`の出力結果から、クラスターの 2 種類のノードの InfiniBand 構成が異なっていることがわかります：
 
-#### V100ノード
+#### V100 ノード
 
 ```
 mlx5_0 port 1 ==> ibxxxxxx0 (Up)
 mlx5_1 port 1 ==> ibxxxxxx1 (Up)
 ```
 
-これらのノードはそれぞれ1つの双方向ポートを持つInfiniBandネットワークカードが搭載されており、各ポートの最大転送速度は100Gbpsで、それぞれ2台の36ポートのInfiniBandスイッチに接続されています。2つのスイッチの間に4本の100Gbpsの接続線があります。
+これらのノードはそれぞれ 1 つの双方向ポートを持つ InfiniBand ネットワークカードが搭載されており、各ポートの最大転送速度は 100Gbps で、それぞれ 2 台の 36 ポートの InfiniBand スイッチに接続されています。2 つのスイッチの間に 4 本の 100Gbps の接続線があります。
 
-- 各ノードには2つの独立したInfiniBandポート（mlx5_0とmlx5_1）があります。
-- 2つのポートはどちらもUp状態です。
+- 各ノードには 2 つの独立した InfiniBand ポート（mlx5_0 と mlx5_1）があります。
+- 2 つのポートはどちらも Up 状態です。
 
-#### A100ノード
+#### A100 ノード
 
 ```
 mlx5_0 port 1 ==> ibxxxx0 (Down/Up)
@@ -90,36 +90,36 @@ mlx5_1 port 1 ==> ibxxxxx0 (Up/Down)
 mlx5_bond_0 port 1 ==> bond0 (Up)
 ```
 
-これらの機械はそれぞれ2枚の200GbpsのInfiniBandカードが搭載されており、1つのInfiniBandスイッチで接続されています。ただし、すべてのネットワークカードが通っているわけではありません。各ノードでは、1つのInfiniBandカードがInfiniBandケーブルを通じてスイッチに接続されています。
+これらの機械はそれぞれ 2 枚の 200Gbps の InfiniBand カードが搭載されており、1 つの InfiniBand スイッチで接続されています。ただし、すべてのネットワークカードが通っているわけではありません。各ノードでは、1 つの InfiniBand カードが InfiniBand ケーブルを通じてスイッチに接続されています。
 
-mlx5_bond_0はイーサネットネットワークカードです。ただ、偶然Mellanox製品のため表示されています。
+mlx5_bond_0 はイーサネットネットワークカードです。ただ、偶然 Mellanox 製品のため表示されています。
 
-KubernetesでRDMAデバイスプラグインをインストールする際には、ネットワークインターフェース情報が必要になります。
+Kubernetes で RDMA デバイスプラグインをインストールする際には、ネットワークインターフェース情報が必要になります。
 
-## Nvidia Network Operatorのインストール
+## Nvidia Network Operator のインストール
 
-> [!quote] [Vanilla KubernetesクラスタでのNetwork Operatorの展開](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-on-vanilla-kubernetes-cluster)
+> [!quote] [Vanilla Kubernetes クラスタでの Network Operator の展開](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-on-vanilla-kubernetes-cluster)
 
-現在、KubernetesでRDMAを統合するための最推奨方法は、Nvidia Network Operatorを使用することです。公式ドキュメントに従って、まずHelmを使用してOperatorのメインプログラムをインストールします。その後、どのRDMA接続方法を採用するかは、再び1つのCRを展開することで実現します。
+現在、Kubernetes で RDMA を統合するための最推奨方法は、Nvidia Network Operator を使用することです。公式ドキュメントに従って、まず Helm を使用して Operator のメインプログラムをインストールします。その後、どの RDMA 接続方法を採用するかは、再び 1 つの CR を展開することで実現します。
 
-まずHelmリポジトリを追加します：
+まず Helm リポジトリを追加します：
 
 ```bash
 helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
 ```
 
-次にドキュメントに従って、`values.yaml`をローカルにダウンロードします。主にNFDを無効にする必要があるかどうか、およびイメージを国内アクセス可能なイメージアドレスに置き換える必要があります。
+次にドキュメントに従って、`values.yaml`をローカルにダウンロードします。主に NFD を無効にする必要があるかどうか、およびイメージを国内アクセス可能なイメージアドレスに置き換える必要があります。
 
-我々のクラスターではすでにNvidia GPU Operatorが展開されているため、NFDオプションを無効にします。
+我々のクラスターではすでに Nvidia GPU Operator が展開されているため、NFD オプションを無効にします。
 
 > [!warning]
-> Operatorの展開中にカスタムリソースを作成する際、いくつかのパラメータを提供する必要があります。そのため、構成ファイルを使用することをお勧めします。CLIでパラメータを上書きすることも可能ですが、構成ファイルを好むことをお勧めします。
+> Operator の展開中にカスタムリソースを作成する際、いくつかのパラメータを提供する必要があります。そのため、構成ファイルを使用することをお勧めします。CLI でパラメータを上書きすることも可能ですが、構成ファイルを好むことをお勧めします。
 
 ```bash
 helm show values nvidia/network-operator --version v25.1.0 > values.yaml
 ```
 
-その後、最新バージョン（v25.1.0）のNvidia Network Operatorをインストールします：
+その後、最新バージョン（v25.1.0）の Nvidia Network Operator をインストールします：
 
 ```bash
 helm upgrade --install network-operator nvidia/network-operator \
@@ -130,7 +130,7 @@ helm upgrade --install network-operator nvidia/network-operator \
 --wait
 ```
 
-インストール後、`nvidia-network-operator`名前空間にOperatorのPodが出現します。この時点でRDMAはまだ設定されておらず、具体的なポリシーと合わせる必要があります。
+インストール後、`nvidia-network-operator`名前空間に Operator の Pod が出現します。この時点で RDMA はまだ設定されておらず、具体的なポリシーと合わせる必要があります。
 
 ```bash
 $ kubectl get pods -l app.kubernetes.io/name=network-operator
@@ -142,29 +142,29 @@ network-operator-xxxxxxxx-xxxxx   1/1     Running   1 (22h ago)   26h
 
 初心者にとって、このドキュメントは実に難解です：
 
-Deployment Examples（展開例）の章で、約20種類の展開方法が紹介されています。では——
+Deployment Examples（展開例）の章で、約 20 種類の展開方法が紹介されています。では——
 
 1. これらの展開方法は性能上有何の違いがありますか？
 2. 自分に合った展開方法を選ぶにはどうすればよいですか？
-3. 展開後、PodがRDMAなどの高性能ネットワークに接続するにはどうすればよいですか？
-4. コンテナでRDMAネットワークをテストするための最低要件は何ですか？
-5. コンテナ内でRDMAネットワークをテストするにはどうすればよいですか？
+3. 展開後、Pod が RDMA などの高性能ネットワークに接続するにはどうすればよいですか？
+4. コンテナで RDMA ネットワークをテストするための最低要件は何ですか？
+5. コンテナ内で RDMA ネットワークをテストするにはどうすればよいですか？
 6. 一般的なエラーとその解決策はどれですか？
 
 ドキュメントではこれらの質問に答えていません。そのため、私の試行錯誤も非常に困難でした。まず、この段階でこれらの質問に対する私の理解と参考資料を簡単にまとめます：
 
-- **性能差**：[IPoIB (IP over InfiniBand) vs. RDMA performance](https://serverfault.com/questions/876403/ipoib-ip-over-infiniband-vs-rdma-performance)、さらにShared Device Pluginが1つのPodがリソースを申請した場合、帯域幅はほぼ満たすことができます。複数の状況についてはまだテストしていません。
-- **展開方法**：現在はRDMA Shared Device Pluginの方法を採用しており、V100上で正常に動作しています。ただし、この方法が結合されたネットワークカードを使用できるかは不明で、将来的にはHost Networkモードに切り替えるかもしれません。
-- **リソース申請**：インストール後、ノードにRDMAに関連するリソースが追加され、いくつかの場合はAnnotationsで使用する補助ネットワーク（例えばMultusまたはMacvlan？）をマークする必要があります。
-- **最低要件**：[RDMAサポートの確認-機械学習プラットフォーム-火山エンジン](https://www.volcengine.com/docs/6459/119595)
-- **テスト方法**：[RDMAワークロードおよびGPU-Direct RDMAワークロードを実行するクラスターの準備](https://github.com/Mellanox/network-operator/tree/master/example)
+- **性能差**：[IPoIB (IP over InfiniBand) vs. RDMA performance](https://serverfault.com/questions/876403/ipoib-ip-over-infiniband-vs-rdma-performance)、さらに Shared Device Plugin が 1 つの Pod がリソースを申請した場合、帯域幅はほぼ満たすことができます。複数の状況についてはまだテストしていません。
+- **展開方法**：現在は RDMA Shared Device Plugin の方法を採用しており、V100 上で正常に動作しています。ただし、この方法が結合されたネットワークカードを使用できるかは不明で、将来的には Host Network モードに切り替えるかもしれません。
+- **リソース申請**：インストール後、ノードに RDMA に関連するリソースが追加され、いくつかの場合は Annotations で使用する補助ネットワーク（例えば Multus または Macvlan？）をマークする必要があります。
+- **最低要件**：[RDMA サポートの確認 - 機械学習プラットフォーム - 火山エンジン](https://www.volcengine.com/docs/6459/119595)
+- **テスト方法**：[RDMA ワークロードおよび GPU-Direct RDMA ワークロードを実行するクラスターの準備](https://github.com/Mellanox/network-operator/tree/master/example)
 - **エラーと解決策**：本文末尾に記載
 
-### 1. RDMA Shared Device Pluginの設定を試みる
+### 1. RDMA Shared Device Plugin の設定を試みる
 
-> [!quote] [RDMA Shared Device Pluginを使用したNetwork Operatorの展開（複数リソース）](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-with-multiple-resources-in-rdma-shared-device-plugin)
+> [!quote] [RDMA Shared Device Plugin を使用した Network Operator の展開（複数リソース）](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-with-multiple-resources-in-rdma-shared-device-plugin)
 
-私の単一クラスターにはV100とA100の2つの異なるIBネットワークが存在するため、ドキュメントで述べられているMultiple Resourcesの設定方法を採用し、V100とA100のポートをそれぞれ指定して、`rdma/rdma_v100`と`rdma/rdma_a100`のネットワークリソースを報告します。
+私の単一クラスターには V100 と A100 の 2 つの異なる IB ネットワークが存在するため、ドキュメントで述べられている Multiple Resources の設定方法を採用し、V100 と A100 のポートをそれぞれ指定して、`rdma/rdma_v100`と`rdma/rdma_a100`のネットワークリソースを報告します。
 
 ```yaml
 apiVersion: mellanox.com/v1alpha1
@@ -204,8 +204,8 @@ spec:
     image: k8s-rdma-shared-dev-plugin
     version: v1.5.2
     imagePullSecrets: []
-    # 下記の設定はk8s-rdma-shared-device-pluginの設定に直接反映されます。
-    # "devices"をRDMA対応ネットワークデバイス名に置き換えてください。
+    # 下記の設定は k8s-rdma-shared-device-plugin の設定に直接反映されます。
+    # "devices"を RDMA 対応ネットワークデバイス名に置き換えてください。
     config: |
       {
         "configList": [
@@ -229,7 +229,7 @@ spec:
       }
 ```
 
-展開後、DaemonSetsが起動しました。NFD機能のおかげで、IBカード（15b3）を持たないノードにはインストールされません。
+展開後、DaemonSets が起動しました。NFD 機能のおかげで、IB カード（15b3）を持たないノードにはインストールされません。
 
 ```bash
 $ kg daemonset
@@ -238,9 +238,9 @@ mofed-ubuntu22.04-xxxxxxxxx-ds   36        36        36      36           36
 rdma-shared-dp-ds                 36        36        36      36           36          feature.node.kubernetes.io/pci-15b3.present=true,network.nvidia.com/operator.mofed.wait=false
 ```
 
-Nvidia Network OperatorのインストールにはOfedドライバとDevice Pluginが含まれています。前者は特権が必要で、ホストマシンのIBドライバに影響を与えます。私のテストの過程で、1台のA100ノードのIBカードが大量のエラーを報告し、エラーログでシステムディスクが埋まり、数時間のサービスが中断しました。
+Nvidia Network Operator のインストールには Ofed ドライバと Device Plugin が含まれています。前者は特権が必要で、ホストマシンの IB ドライバに影響を与えます。私のテストの過程で、1 台の A100 ノードの IB カードが大量のエラーを報告し、エラーログでシステムディスクが埋まり、数時間のサービスが中断しました。
 
-すべてのPodがRunning状態になった後、ノード上で新規リソースが追加されているかを確認します：
+すべての Pod が Running 状態になった後、ノード上で新規リソースが追加されているかを確認します：
 
 ```bash
 $ kubectl get nodes -o json | jq -r '.items[] | {
@@ -258,35 +258,35 @@ $ kubectl get nodes -o json | jq -r '.items[] | {
 }
 ```
 
-これでRDMA Shared Device Pluginに基づくインストール方法は一段落です。字節跳動の火山エンジンの中にはこの方法が使われているようです。
+これで RDMA Shared Device Plugin に基づくインストール方法は一段落です。字節跳動の火山エンジンの中にはこの方法が使われているようです。
 
-### 2. GPUDirect Workloadsの設定を試みる（未成功）
+### 2. GPUDirect Workloads の設定を試みる（未成功）
 
-> [!quote] [GPUDirectワークロード用のNetwork Operatorの展開](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-for-gpudirect-workloads)
+> [!quote] [GPUDirect ワークロード用の Network Operator の展開](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-for-gpudirect-workloads)
 
-本節はプロセス中の失敗した試みを記録したものです。RDMA Shared Device Plugin後の検証に興味がある場合は、次の節に直接移動してください。
+本節はプロセス中の失敗した試みを記録したものです。RDMA Shared Device Plugin 後の検証に興味がある場合は、次の節に直接移動してください。
 
-RDMA Shared Device Plugin（以下方法1）の設定中にいくつかの問題に遭遇し、方法1の道が通らないと誤って思い込み、K8s RDMA Shared Dev Pluginプロジェクトのディスカッション掲示板にも以下のコメントがありました[^3]（ただし、下に反例が存在し、当時は調節できず、すでに古くなったと感じていました）：
+RDMA Shared Device Plugin（以下方法 1）の設定中にいくつかの問題に遭遇し、方法 1 の道が通らないと誤って思い込み、K8s RDMA Shared Dev Plugin プロジェクトのディスカッション掲示板にも以下のコメントがありました[^3]（ただし、下に反例が存在し、当時は調節できず、すでに古くなったと感じていました）：
 
 > [!quote] [Adrian Chiris](https://github.com/adrianchiris)
 >
-> プロジェクトのREADMEを改善すべきです。
+> プロジェクトの README を改善すべきです。
 >
-> Kubernetesと併用する一般的な方法は、macvlanやipoib（または、基本的にRDMA対応の既存親netdevの上に仮想インターフェースを作成できる任意のCNI）などの補助ネットワークCNIを使用することです。
-> **Kubernetesと併用する一般的な方法は、macvlanやipoib（または、基本的にRDMA対応の既存親netdevの上に仮想インターフェースを作成できる任意のCNI）などの補助ネットワークCNIを使用することです。**
+> Kubernetes と併用する一般的な方法は、macvlan や ipoib（または、基本的に RDMA 対応の既存親 netdev の上に仮想インターフェースを作成できる任意の CNI）などの補助ネットワーク CNI を使用することです。
+> **Kubernetes と併用する一般的な方法は、macvlan や ipoib（または、基本的に RDMA 対応の既存親 netdev の上に仮想インターフェースを作成できる任意の CNI）などの補助ネットワーク CNI を使用することです。**
 >
 > その指示と例を更新すべきです。
 
-またドキュメントを読み直し、一節「GPUDirect Workloads」がありました（内心OS：他のインストール方法はすべてGPU Workloadsではないのでしょうか？）。
+またドキュメントを読み直し、一節「GPUDirect Workloads」がありました（内心 OS：他のインストール方法はすべて GPU Workloads ではないのでしょうか？）。
 
-方法1と比較して、この方法はDOCAドライバ、SR-IOV Device Plugin、Secondary network、Multus CNI、Container Networking plugins、IPAM pluginをインストールする必要があります。その中でMultus CNIはKubernetesにおいて補助ネットワークCNI[^4]です。
+方法 1 と比較して、この方法は DOCA ドライバ、SR-IOV Device Plugin、Secondary network、Multus CNI、Container Networking plugins、IPAM plugin をインストールする必要があります。その中で Multus CNI は Kubernetes において補助ネットワーク CNI[^4]です。
 
 > [!quote]
 >
-> - **Multus**はCNI（コンテナネットワークインターフェース）プラグインで、1つのKubernetes Podに複数のネットワークインターフェースを挿入することができ、より柔軟なネットワーク通信を実現します。Flannel、Calico、Macvlanなどの複数のCNIプラグインをサポートし、他のネットワークソリューションと非常に良い統合性を持っています。あるシナリオでは、Podが複数の異なるネットワークに同時に接続する必要がある場合、Multusはそのような機能を実現し、Podに複数のネットワークインターフェースを提供して、異なるネットワークと通信できるようにします。
-> - **Whereabouts**はIPアドレス管理ツールで、Podに自動的にIPアドレスを割り当て、IPアドレスの衝突を防ぐことができます。伝統的なネットワーク設定では、各ホストに異なるIPアドレス範囲を手動で割り当てることで、IPアドレスの衝突を防ぐ必要があります。Whereaboutsは自動化されたIPアドレス割り当てメカニズムにより、このプロセスを簡略化し、Kubernetesクラスター内のIPアドレス管理をより効率的かつ信頼性高く行うことができます。これにより、各Podが一意のIPアドレスを獲得でき、大規模なクラスター環境でもIPアドレスの重複を効果的に防ぐことができます。
+> - **Multus**は CNI（コンテナネットワークインターフェース）プラグインで、1 つの Kubernetes Pod に複数のネットワークインターフェースを挿入することができ、より柔軟なネットワーク通信を実現します。Flannel、Calico、Macvlan などの複数の CNI プラグインをサポートし、他のネットワークソリューションと非常に良い統合性を持っています。あるシナリオでは、Pod が複数の異なるネットワークに同時に接続する必要がある場合、Multus はそのような機能を実現し、Pod に複数のネットワークインターフェースを提供して、異なるネットワークと通信できるようにします。
+> - **Whereabouts**は IP アドレス管理ツールで、Pod に自動的に IP アドレスを割り当て、IP アドレスの衝突を防ぐことができます。伝統的なネットワーク設定では、各ホストに異なる IP アドレス範囲を手動で割り当てることで、IP アドレスの衝突を防ぐ必要があります。Whereabouts は自動化された IP アドレス割り当てメカニズムにより、このプロセスを簡略化し、Kubernetes クラスター内の IP アドレス管理をより効率的かつ信頼性高く行うことができます。これにより、各 Pod が一意の IP アドレスを獲得でき、大規模なクラスター環境でも IP アドレスの重複を効果的に防ぐことができます。
 
-展開時にはまずNic Cluster Policyをインストールします：
+展開時にはまず Nic Cluster Policy をインストールします：
 
 ```yaml
 apiVersion: mellanox.com/v1alpha1
@@ -362,7 +362,7 @@ spec:
       imagePullSecrets: []
 ```
 
-その後、Where Aboutsで割り当て可能なIPを指定し、現在の二層ネットワーク下で使用されているIPと重複しないようにする必要があります（これはMetal LBがやっていることと似ています？）。そのため、まずスキャンを行い、使用されていない小さなIPセグメントを選び出しました。
+その後、Where Abouts で割り当て可能な IP を指定し、現在の二層ネットワーク下で使用されている IP と重複しないようにする必要があります（これは Metal LB がやっていることと似ています？）。そのため、まずスキャンを行い、使用されていない小さな IP セグメントを選び出しました。
 
 ```yaml
 apiVersion: mellanox.com/v1alpha1
@@ -370,7 +370,7 @@ kind: HostDeviceNetwork
 metadata:
   name: hostdevice-net
 spec:
-  networkNamespace: "crater-workspace" # Workloadsが存在する名前空間
+  networkNamespace: "crater-workspace" # Workloads が存在する名前空間
   resourceName: "hostdev"
   ipam: |
     {
@@ -404,7 +404,7 @@ $ kubectl get nodes -o json | jq -r '.items[] | {
 }
 ```
 
-この特殊なネットワークを使用するには、Podを提出するときにAnnotationを追加する必要があります：
+この特殊なネットワークを使用するには、Pod を提出するときに Annotation を追加する必要があります：
 
 ```yaml
 apiVersion: v1
@@ -435,18 +435,18 @@ spec:
           nvidia.com/gpu: "1"
 ```
 
-Podに入ったら、`ifconfig`コマンドを実行して、`net1`という名前のネットワークインターフェースが追加されていることに気づきます。しかし、次に何をするべきでしょうか？Network Operatorのプロジェクトリポジトリにテストファイル[^5]が提供されていますが、コマンドも`sleep inf`です。
+Pod に入ったら、`ifconfig`コマンドを実行して、`net1`という名前のネットワークインターフェースが追加されていることに気づきます。しかし、次に何をするべきでしょうか？Network Operator のプロジェクトリポジトリにテストファイル[^5]が提供されていますが、コマンドも`sleep inf`です。
 
-私はおそらくNCCLがネットワークインターフェースを指定する必要があるかもしれません。その後、RDMA Shared Device Pluginが動作したため、この部分の研究は深く進めませんでした。公式に疑問を提出することも良い選択肢かもしれません。
+私はおそらく NCCL がネットワークインターフェースを指定する必要があるかもしれません。その後、RDMA Shared Device Plugin が動作したため、この部分の研究は深く進めませんでした。公式に疑問を提出することも良い選択肢かもしれません。
 
-古いリソースをクリーンアップするには、1つのターミナルで`kubectl proxy`を起動します：
+古いリソースをクリーンアップするには、1 つのターミナルで`kubectl proxy`を起動します：
 
 ```shell
 $ kubectl proxy
 Starting to serve on 127.0.0.1:8001
 ```
 
-もう1つのターミナルでクリーンアップスクリプトを実行します（`/`は`~1`としてエスケープする必要があります）：
+もう 1 つのターミナルでクリーンアップスクリプトを実行します（`/`は`~1`としてエスケープする必要があります）：
 
 ```bash
 #!/bin/bash
@@ -485,15 +485,15 @@ chmod +x ./patch_node_gpu.sh
 ./patch_node_gpu.sh node1 node2
 ```
 
-## RDMAのインストールを検証する
+## RDMA のインストールを検証する
 
-この節では、RDMA Shared Device Pluginに基づいた方法でRDMAのインストールをどのように検証するかを説明します。
+この節では、RDMA Shared Device Plugin に基づいた方法で RDMA のインストールをどのように検証するかを説明します。
 
-### 1. RDMAをサポートするイメージの準備
+### 1. RDMA をサポートするイメージの準備
 
-> [!quote] [RDMAサポートの確認-機械学習プラットフォーム-火山エンジン](https://www.volcengine.com/docs/6459/119595)
+> [!quote] [RDMA サポートの確認 - 機械学習プラットフォーム - 火山エンジン](https://www.volcengine.com/docs/6459/119595)
 
-V100モデルに適用できる簡単なDockerfileは以下の通りです：
+V100 モデルに適用できる簡単な Dockerfile は以下の通りです：
 
 ```dockerfile
 FROM xxx/envd:py3.12-ubuntu22.04-8978
@@ -508,13 +508,13 @@ RUN apt-get update && apt-get install -y \
 # Python依存関係は指定されていません
 ```
 
-この私のベースイメージにはすでに一般的なデバッグツールキット、Python、CUDA環境が含まれています。主にAPTを介してInfiniBand関連のライブラリを追加します。
+この私のベースイメージにはすでに一般的なデバッグツールキット、Python、CUDA 環境が含まれています。主に APT を介して InfiniBand 関連のライブラリを追加します。
 
-これらのライブラリをインストールした後、RDMAリソースを申請せずにPodを起動する場合、`ibstat`の内容を正常に表示できます。しかし、書き込みなどの操作を試みると、InfiniBandまたはRoCEデバイスが存在しないとエラーになります。
+これらのライブラリをインストールした後、RDMA リソースを申請せずに Pod を起動する場合、`ibstat`の内容を正常に表示できます。しかし、書き込みなどの操作を試みると、InfiniBand または RoCE デバイスが存在しないとエラーになります。
 
 ### 2. 単一マシンでの検証方法
 
-まずRDMAリソースを申請したPodを起動する必要があります：
+まず RDMA リソースを申請した Pod を起動する必要があります：
 
 ```yaml
 apiVersion: v1
@@ -542,7 +542,7 @@ spec:
       sleep infinity
 ```
 
-ここでは通常のGPUリソースに対してモデルごとにリネームしています。関連情報は以前の記事を参照してください。
+ここでは通常の GPU リソースに対してモデルごとにリネームしています。関連情報は以前の記事を参照してください。
 
 コンテナが起動成功後、コンテナに入ります：
 
@@ -618,11 +618,11 @@ Conflicting CPU frequency values detected: 1000.000000 != 3013.932000. CPU Frequ
 [1]+  Done                    ib_write_bw -d mlx5_1
 ```
 
-V100 RDMAモデルの場合、帯域幅値（`BW peak`、`BW average`）は`100Gb/s`に近づくべきです。A100 RDMAモデルは`200Gb/s`に近づくべきです。もし要件に合っていれば設定は問題ありません。出力がないかエラーがある場合は、機種に応じた環境設定の部分に戻って、設定項目が欠けているか確認してください。
+V100 RDMA モデルの場合、帯域幅値（`BW peak`、`BW average`）は`100Gb/s`に近づくべきです。A100 RDMA モデルは`200Gb/s`に近づくべきです。もし要件に合っていれば設定は問題ありません。出力がないかエラーがある場合は、機種に応じた環境設定の部分に戻って、設定項目が欠けているか確認してください。
 
 ### 3. 複数マシンでの検証方法
 
-第2節と同様に、それぞれに2つのPodを申請し、そのうちの1つのPodのKubernetes内ネットワークIPを記録します。その後、コマンドを実行します：
+第 2 節と同様に、それぞれに 2 つの Pod を申請し、そのうちの 1 つの Pod の Kubernetes 内ネットワーク IP を記録します。その後、コマンドを実行します：
 
 ```bash
 # サーバーコマンド
@@ -634,9 +634,9 @@ ib_write_bw -a -F --report_gbits -q 2 <server-pod-default-network-IP>
 
 帯域幅値も`100Gb/s`に近づくため、複数マシン間の接続に問題がないことを示します。
 
-### 4. vLLM複数マシン分散推論の実践
+### 4. vLLM 複数マシン分散推論の実践
 
-最後に、Volcano Jobを通じてvLLM複数マシン分散推論DeepSeek R1 Distill Qwen 32Bモデルを実測します。モデルはPVCでマウントし、イメージはEnvdで作成します。vLLMは専用のCUDA 12.4をインストールするため、基本イメージにはCUDAを含めません。
+最後に、Volcano Job を通じて vLLM 複数マシン分散推論 DeepSeek R1 Distill Qwen 32B モデルを実測します。モデルは PVC でマウントし、イメージは Envd で作成します。vLLM は専用の CUDA 12.4 をインストールするため、基本イメージには CUDA を含めません。
 
 ```python
 # syntax=v1
@@ -654,7 +654,7 @@ def build():
     config.jupyter()
 ```
 
-その後、Volcano Jobを起動します：
+その後、Volcano Job を起動します：
 
 ```yaml
 apiVersion: batch.volcano.sh/v1alpha1
