diff --git crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.jp.md crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.jp.md
index 3db29bd..a97f5b6 100644
--- crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.jp.md
+++ crater-website/content/docs/user/toolbox/deepseek/dis-deepseek-32b.jp.md
@@ -40,19 +40,19 @@ NCCL_DEBUG=TRACE python3 -m vllm.entrypoints.openai.api_server \
 
 ### よくある問題
 
-> 問題1: ValueError: Bfloat16は、少なくとも計算能力8.0のGPUのみでサポートされます。あなたのTesla V100-SXM2-32GB GPUは計算能力7.0です。CLIでdtypeフラグを明示的に設定してfloat16を使用することができるので、たとえば --dtype=half と設定してください。
+> 問題 1: ValueError: Bfloat16 は、少なくとも計算能力 8.0 の GPU のみでサポートされます。あなたの Tesla V100-SXM2-32GB GPU は計算能力 7.0 です。CLI で dtype フラグを明示的に設定して float16 を使用することができるので、たとえば --dtype=half と設定してください。
 
-回答1: vLLMの起動パラメータに--dtype=halfを追加してください。この問題の主な原因は、多くの加速演算子がv100では動かないため、多くの高性能演算子にはハードウェア制限があるためです。
+回答 1: vLLM の起動パラメータに--dtype=half を追加してください。この問題の主な原因は、多くの加速演算子が v100 では動かないため、多くの高性能演算子にはハードウェア制限があるためです。
 
-> 問題2: 必要な計算リソース量をどのように予測すればよいですか？
+> 問題 2: 必要な計算リソース量をどのように予測すればよいですか？
 
-回答2: メモリ使用量（最小）>= モデルパラメータ数 × 配置ビット数(bit) / 8 です。例えば、インスタンスで32bモデルを使用し、16bitで配置する場合、少なくとも64GBのメモリが必要です。craterで使用する1枚のv100のメモリは32GBなので、実際には3〜4枚のv100で動かすことが可能です。これはテスト用に複数マシンを用意したため、8枚のGPUを使用しています。
+回答 2: メモリ使用量（最小）>= モデルパラメータ数 × 配置ビット数 (bit) / 8 です。例えば、インスタンスで 32b モデルを使用し、16bit で配置する場合、少なくとも 64GB のメモリが必要です。crater で使用する 1 枚の v100 のメモリは 32GB なので、実際には 3〜4 枚の v100 で動かすことが可能です。これはテスト用に複数マシンを用意したため、8 枚の GPU を使用しています。
 
-> 問題3: sglangを使用できますか？
+> 問題 3: sglang を使用できますか？
 
-回答3: sglangフレームワークは7.0のGPUを使用してデプロイすることはできません。また、vllmの一部の機能はv100で使用することはできません（具体的にはvllmのドキュメントやissueセクションをご覧ください）。
+回答 3: sglang フレームワークは 7.0 の GPU を使用してデプロイすることはできません。また、vllm の一部の機能は v100 で使用することはできません（具体的には vllm のドキュメントや issue セクションをご覧ください）。
 
-これで、ジョブテンプレートを使用して高速に展開したDeepSeek R1 32bモデルと対話できます 🥳！
+これで、ジョブテンプレートを使用して高速に展開した DeepSeek R1 32b モデルと対話できます 🥳！
 
 ## Web UI インターフェースの起動と大規模モデルとの対話
 
@@ -66,11 +66,11 @@ NCCL_DEBUG=TRACE python3 -m vllm.entrypoints.openai.api_server \
 
 ![](./img/dis-deepseek-32b/openweb-submit.webp)
 
-Crater プラットフォームで **DeepSeek R1 分散推論** のタスクテンプレートを使用して大規模モデル推論サービスを起動した後、環境変数の最初の行を編集する必要があります。OpenAIサービスのアドレスは、作業の「基本情報」に記載されている **Ray Headノードの「内網IP」** です。
+Crater プラットフォームで **DeepSeek R1 分散推論** のタスクテンプレートを使用して大規模モデル推論サービスを起動した後、環境変数の最初の行を編集する必要があります。OpenAI サービスのアドレスは、作業の「基本情報」に記載されている **Ray Head ノードの「内網 IP」** です。
 
 ![](./img/dis-deepseek-32b/dis-ip.webp)
 
-Open WebUIが正常に起動後、詳細ページに移動し、「外部アクセス」をクリックしてください。すでに転送設定を行っていますので、クリックするだけでアクセスできます。
+Open WebUI が正常に起動後、詳細ページに移動し、「外部アクセス」をクリックしてください。すでに転送設定を行っていますので、クリックするだけでアクセスできます。
 
 ![](./img/dis-deepseek-32b/openweb-fw.webp)
 
