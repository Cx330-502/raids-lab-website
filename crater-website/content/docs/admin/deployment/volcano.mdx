---
title: Volcano 集成指南
description: Crater 如何使用 Volcano 批处理调度器进行多实验室 GPU 资源管理及分布式工作负载。

---

## 概述

[Volcano](https://volcano.sh/zh/) 是一个为高性能工作负载（如 AI/ML 训练、大数据和科学计算）设计的批处理调度系统。在 Crater 中，Volcano 以公平且抢占的方式管理多个实验室和用户之间的 GPU 调度。

---

## 为什么选择 Volcano？

我们选择 Volcano 用于 Crater，是因为它丰富的调度功能、可扩展的插件系统，以及对 **分布式训练**、**公平资源共享** 和 **任务级控制** 的原生支持。

Crater 使用了以下 Volcano 组件：

- **队列与配额 CRDs** – 在多个实验室之间实现细粒度的 GPU 资源分配
- **抢占（容量插件）** – 在实验室和用户之间进行抢占式调度
- **Job CRD 与插件** – 原生支持分布式任务
- **节点排序、任务排序、组调度** 等

---

## 面向实验室的队列设计

Crater 面向的是一个学术多租户场景，其中 GPU 集群由多个研究实验室共享。为了管理资源公平性：

- 我们为每个实验室创建一个 **`Queue`**（例如，`lab-a`、`lab-b`）
- 每个用户被分配到其所属实验室的队列中
- 相应的 **`ResourceQuota`** 定义了实验室的保证 GPU 容量
- Volcano 的 **`capacity` 插件** 在发生资源争用时执行抢占策略

这种设计可以实现：

- 实验室之间清晰的 **资源边界**
- 允许机会性共享的 **软配额**
- 避免资源饥饿的 **基于优先级的抢占**

---

## 支持分布式任务

Crater 使用 Volcano 的 [Job CRD](https://volcano.sh/zh/docs/job-tutorial/) 支持：

- 分布式 PyTorch、TensorFlow 或 MPI 工作负载
- 组调度和任务依赖
- 生命周期管理（启动、挂起、删除）

我们还在 Volcano 中启用了以下调度插件：

- `gang` – 确保同一任务中的 Pod 同时启动
- `svc` – 为分布式训练生成无头服务
- `priority` – 遵循用户/任务优先级
- `numa-aware` – 可选，适用于对性能敏感的工作负载

---

## VLLM 兼容性

我们目前正在通过自定义的 `Job` CRDs 将 [vLLM](https://github.com/vllm-project/vllm) 推理引擎适配到 Volcano 下运行。这使我们能够将大型模型推理视为一个具有集成调度、排队和配额执行的分布式工作负载。

---

## LLaMA Factory 兼容性

我们还在积极扩展对 [LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory) 的支持，这是 ACT Lab 开发的另一个微调项目。集成工作重点是使用 Volcano 的 `Job` CRD 启用分布式微调任务，并具备对 GPU 拓扑、资源配额和任务编排的调度感知能力。

---

## 安装说明

我们建议通过 Helm 并使用 Crater 的预配置值来安装 Volcano。

📦 Helm 值：[`deployments/volcano/values.yaml`](../deployments/volcano/values.yaml)  
📖 详细指南：[`deployments/volcano/README.md`](../deployments/volcano/README.md)