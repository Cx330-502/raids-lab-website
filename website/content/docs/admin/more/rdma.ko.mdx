---
title: "RDMA 지원"
description: "RDMA"
---

> - [K8s test via Infiniband network - Adapters and Cables / InfiniBand/VPI Adapter Cards - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/k8s-test-via-infiniband-network/285610)
> - [Running tightly coupled HPC/AI workloads with InfiniBand using NVIDIA Network Operator on AKS | Microsoft Community Hub](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/running-tightly-coupled-hpcai-workloads-with-infiniband-using-nvidia-network-ope/4117209)
> - [Basic Knowledge and Differences of RoCE, IB, and TCP Networks](https://support.huawei.com/enterprise/en/doc/EDOC1100203339)

공식적으로 시작하기 전에 RDMA 와 관련된 기본 지식을 보완하겠습니다:

- **RDMA**: 운영체제 커널을 우회하는 네트워크 통신 기술로, 주요 기능은 네트워크 카드를 통해 원격 메모리에 직접 접근하여 전통적인 TCP/IP 프로토콜 스택의 데이터 복사 및 컨텍스트 전환 비용을 피하는 것입니다.
- **NVIDIA GPU Direct**[^2]: GPU 메모리와 네트워크 카드의 DMA 엔진을 직접 연결하여 GPU 가 원격 노드와 통신할 때 데이터를 InfiniBand 또는 RoCE 네트워크 카드를 통해 직접 전송할 수 있게 하며, 호스트 메모리를 통해 중계할 필요가 없습니다.
- **네트워크 가상화**: Macvlan 과 SR-IOV 는 네트워크 가상화의 두 가지 일반적인 방법입니다. Macvlan 은 컨테이너에 가상 네트워크 인터페이스를 생성하여 물리 네트워크에서 독립 장치처럼 표시할 수 있도록 합니다. SR-IOV 는 물리 네트워크 카드의 하드웨어 가상화 기능을 활용하여 단일 물리 기능 (PF) 을 여러 가상 기능 (VF) 으로 나누고, 각 VF 는 Pod 에 직접 할당할 수 있습니다.
- **기술 경로**: 현재 RDMA 는 InfiniBand 와 RoCE 의 두 가지 주요 구현 방식[^6]이 있습니다. InfiniBand 는 원생 RDMA 프로토콜을 지원하지만, 전용 스위치와 서브넷 관리자로 독립 네트워크를 구성해야 하므로 비용이 많이 들며, RoCEv2 는 전통적인 이더넷 인프라를 기반으로 PFC 및 ECN 등의 흐름 제어 메커니즘을 통해 무손실 전송을 보장하며, 인터넷 회사에서 널리 사용되고 있습니다.

우리 실험실에서는 InfiniBand 방식을 사용하고 있습니다. 따라서 먼저 관련 장비의 IB 정보를 확인해 보겠습니다:

### 1. 단일 노드에서 InfiniBand 관련 정보 테스트

먼저 호스트 머신에서 테스트를 수행합니다. 클라우드로 올라가기 전에 이 머신의 IB 는 모두 통신이 가능했습니다:

```bash
$ ibdev2netdev
mlx5_0 port 1 ==> ibxxxxxx0 (Up)
mlx5_1 port 1 ==> ibxxxxxx1 (Up)

$ ibstat
CA 'mlx5_0'
        Port 1:
                Link layer: InfiniBand
CA 'mlx5_1'
        Port 1:
                Link layer: InfiniBand
```

- **Up**: 해당 InfiniBand 포트가 성공적으로 활성화되었으며 네트워크와 연결된 상태를 나타냅니다
- **Down**: 해당 InfiniBand 포트가 비활성화되었거나 네트워크 연결이 실패한 상태를 나타냅니다

### 2. Ansible 을 사용하여 노드의 네트워크 카드 일괄 확인

그룹 분할:

```toml
[ib-v100]
xx.xx.xx.[xx:xx]

[ib-a100]
xx.xx.xx.[xx:xx]
```

일괄 조회 스크립트 작성:

```yaml
---
- name: Run ibdev2netdev on InfiniBand hosts
  hosts: ib-v100,ib-a100
  gather_facts: no

  tasks:
    - name: Execute ibdev2netdev command
      ansible.builtin.command: ibdev2netdev
      register: ibdev_output
      changed_when: false

    - name: Display ibdev2netdev output
      ansible.builtin.debug:
        var: ibdev_output.stdout_lines
```

반환값이 너무 길어 전체를 붙이지 않겠습니다. `ibdev2netdev`의 출력 결과를 보면 클러스터의 두 종류 노드의 InfiniBand 구성이 다르다는 것을 알 수 있습니다:

#### V100 노드

```
mlx5_0 port 1 ==> ibxxxxxx0 (Up)
mlx5_1 port 1 ==> ibxxxxxx1 (Up)
```

이 노드는 각각 하나의 이중 포트 IB 네트워크 카드가 있으며, 각 포트의 최대 전송률은 100Gbp/s이고, 각각 2 대의 36 포트 IB 스위치에 연결되어 있으며, 두 스위치 간에는 4 개의 100Gbps 인터커넥트 라인이 있습니다.

- 각 노드에는 두 개의 독립적인 InfiniBand 포트 (mlx5_0 및 mlx5_1) 가 있습니다
- 두 포트 모두 Up 상태입니다

#### A100 노드

```
mlx5_0 port 1 ==> ibxxxx0 (Down/Up)
mlx5_1 port 1 ==> ibxxxxx0 (Up/Down)
mlx5_bond_0 port 1 ==> bond0 (Up)
```

이 머신은 각각 2 개의 200Gbps IB 카드가 장착되어 있으며, 하나의 IB 스위치로 연결되어 있습니다. 그러나 모든 네트워크 카드가 통신 가능한 것은 아니며, 각 노드에서는 하나의 IB 카드만 스위치에 연결되어 있습니다.

mlx5_bond_0 은 이더넷 네트워크 카드이지만, Mellanox 제조사의 제품이기 때문에 나타나기도 합니다.

Kubernetes 에서 RDMA 장치 플러그인을 설치할 때는 네트워크 인터페이스 정보가 필요합니다.

## Nvidia Network Operator 설치

> [!quote] [Vanilla Kubernetes 클러스터에서 Network Operator 배포](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-on-vanilla-kubernetes-cluster)

현재 Kubernetes 에서 RDMA 를 통합하는 가장 권장되는 방법은 Nvidia Network Operator 를 사용하는 것입니다. 공식 문서를 참조하여 먼저 Helm 을 통해 Operator 주 프로그램을 설치합니다. 이후 RDMA 접속 방식은 어떤 것을 선택하든, 다시 하나의 CR 을 배포하여 구현할 수 있습니다.

먼저 Helm 저장소를 추가합니다:

```bash
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
```

다음으로 문서를 따라 `values.yaml`을 로컬에 다운로드합니다. 주로 NFD 가 필요한지 여부와, 이미지를 국내에서 접근 가능한 이미지 주소로 교체하는지를 확인합니다.

우리 클러스터에서는 이미 Nvidia GPU Operator 가 설치되어 있으므로, NFD 옵션을 비활성화합니다.

> [!warning]
> Operator 설치 중 사용자 정의 리소스를 생성할 때 여러 파라미터가 제공되어야 하므로, 구성 파일을 사용하는 것이 좋습니다. CLI 를 통해 파라미터를 오버라이드하는 것도 가능하지만, CLI 인수 사용보다는 구성 파일을 권장합니다.

```bash
helm show values nvidia/network-operator --version v25.1.0 > values.yaml
```

그 후 최신 버전 (v25.1.0) 의 Nvidia Network Operator 프로그램을 설치합니다:

```bash
helm upgrade --install network-operator nvidia/network-operator \
-n nvidia-network-operator \
--create-namespace \
--version v25.1.0 \
-f ./values.yaml \
--wait
```

설치 후, `nvidia-network-operator` 네임스페이스에 Operator 의 Pod 가 나타나며, RDMA 는 아직 구성되지 않았습니다. 구체적인 전략을 결합해야 합니다.

```bash
$ kubectl get pods -l app.kubernetes.io/name=network-operator
NAME                               READY   STATUS    RESTARTS      AGE
network-operator-xxxxxxxx-xxxxx   1/1     Running   1 (22h ago)   26h
```

## `NicClusterPolicy` 설정

초보자에게 이 문서는 매우 복잡합니다:

Deployment Examples(배포 예시) 섹션에서 약 20 가지의 배포 방법이 나와 있습니다. 그러면——

1. 이 배포 방법들 간의 성능 차이는 어떻게 되나요?
2. 자신에게 적합한 배포 방법은 어떻게 선택해야 하나요?
3. 배포 후 Pod 가 RDMA 및 기타 고성능 네트워크에 연결되도록 어떻게 해야 하나요?
4. 컨테이너에서 RDMA 네트워크 테스트를 위해 최소한의 요구사항은 무엇인가요?
5. 컨테이너에서 RDMA 네트워크를 테스트하는 방법은 무엇인가요?
6. 일반적인 오류와 해결 방법은 무엇인가요?

문서는 이러한 질문에 답하지 않아, 내 연구도 매우 어렵습니다. 현재 단계에서 이 질문들에 대한 이해와 참고 자료를 빠르게 요약해 보겠습니다:

- **성능 차이**: [IPoIB (IP over InfiniBand) vs. RDMA 성능](https://serverfault.com/questions/876403/ipoib-ip-over-infiniband-vs-rdma-performance), 또한 Shared Device Plugin 이 하나의 Pod 만 리소스를 요청하는 경우 대역폭을 거의 채울 수 있으며, 여러 경우는 아직 테스트하지 않았습니다.
- **배포 방법**: 현재 RDMA Shared Device Plugin 방식을 사용하고 있으며, V100 에서 정상적으로 작동하고 있습니다. 하지만 이 방식이 집합된 네트워크 카드를 사용할 수 있는지 여부는 불확실하며, 이후 Host Network 모드로 전환할 수도 있습니다.
- **리소스 요청**: 설치 후 일반적으로 노드에 RDMA 관련 리소스가 추가되며, 일부 경우에는 Annotations 에 사용할 보조 네트워크 (예: Multus 또는 Macvlan?) 를 표시해야 할 수도 있습니다.
- **최소 요구사항**: [RDMA 지원 여부 확인--머신러닝 플랫폼 - 화산 엔진](https://www.volcengine.com/docs/6459/119595)
- **테스트 방법**: [RDMA 워크로드 및 GPU-Direct RDMA 워크로드를 실행하기 위한 클러스터 준비](https://github.com/Mellanox/network-operator/tree/master/example)
- **오류 및 해결 방법**: 본문의 끝부분에서 확인 가능

### 1. RDMA Shared Device Plugin 설정 시도

> [!quote] [RDMA Shared Device Plugin 에서 여러 리소스 사용하는 Network Operator 배포](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-with-multiple-resources-in-rdma-shared-device-plugin)

제 단일 클러스터에 두 가지 다른 IB 네트워크 (V100 및 A100) 가 존재하므로, 문서에 언급된 Multiple Resources 설정 방법을 사용하여 각각 V100 및 A100 의 포트를 지정하고, `rdma/rdma_v100` 및 `rdma/rdma_a100` 네트워크 리소스를 등록합니다.

```yaml
apiVersion: mellanox.com/v1alpha1
kind: NicClusterPolicy
metadata:
  name: nic-cluster-policy
spec:
  ofedDriver:
    image: doca-driver
    repository: nvcr.io/nvidia/mellanox
    version: 25.01-0.6.0.0-0
    forcePrecompiled: false
    imagePullSecrets: []
    terminationGracePeriodSeconds: 300
    startupProbe:
      initialDelaySeconds: 10
      periodSeconds: 20
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 30
    readinessProbe:
      initialDelaySeconds: 10
      periodSeconds: 30
    upgradePolicy:
      autoUpgrade: true
      maxParallelUpgrades: 1
      safeLoad: false
      drain:
        enable: true
        force: true
        podSelector: ""
        timeoutSeconds: 300
        deleteEmptyDir: true
  rdmaSharedDevicePlugin:
    # [map[ifNames:[ens1f0 ens1f1] name:rdma_shared_device_a] map[ifNames:[ens2f0 ens2f1] name:rdma_shared_device_b]]
    repository: ghcr.io/mellanox
    image: k8s-rdma-shared-dev-plugin
    version: v1.5.2
    imagePullSecrets: []
    # 다음 구성은 직접 k8s-rdma-shared-device-plugin 구성으로 전달됩니다.
    # 'devices'를 (RDMA 가능) 네트워크 장치 이름으로 교체합니다.
    config: |
      {
        "configList": [
          {
            "resourceName": "rdma_v100",
            "rdmaHcaMax": 63,
            "selectors": {
              "ifNames": ["ibxxxxxx0","ibxxxxxx1"],
              "linkTypes": ["infiniband"]
            }
          },
          {
            "resourceName": "rdma_a100",
            "rdmaHcaMax": 63,
            "selectors": {
              "ifNames": ["ibxxxx0","ibxxxxx0"],
              "linkTypes": ["infiniband"]
            }
          }
        ]
      }
```

배포 완료 후, DaemonSets 가 시작됩니다. NFD 기능 덕분에 IB 네트워크 카드 (15b3) 가 없는 노드에서는 설치되지 않습니다.

```bash
$ kg daemonset
NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                                                                                                                                                                                                             AGE
mofed-ubuntu22.04-xxxxxxxxx-ds   36        36        36      36           36          feature.node.kubernetes.io/kernel-version.full=5.15.0-134-generic,feature.node.kubernetes.io/pci-15b3.present=true,feature.node.kubernetes.io/system-os_release.ID=ubuntu,feature.node.kubernetes.io/system-os_release.VERSION_ID=22.04   24h
rdma-shared-dp-ds                 36        36        36      36           36          feature.node.kubernetes.io/pci-15b3.present=true,network.nvidia.com/operator.mofed.wait=false
```

Nvidia Network Operator 설치는 Ofed 드라이버와 Device Plugin 을 포함합니다. 전자는 특권이 필요하며, 호스트 머신의 IB 드라이버에 영향을 줄 수 있습니다. 제 테스트 과정에서 A100 노드의 IB 네트워크 카드에 많은 오류가 발생하여, 오류 로그가 시스템 디스크를 가득 채워 수시간 동안 서비스가 중단되었습니다.

모든 Pod 가 Running 상태가 되면, 노드에 추가된 리소스를 확인합니다:

```bash
$ kubectl get nodes -o json | jq -r '.items[] | {
    name: .metadata.name,
    "rdma/rdma_v100": .status.capacity["rdma/rdma_v100"]
} | select(.["rdma/rdma_v100"] != null)'
# 동일한 결과 생략
{
  "name": "xxx-v100-xx",
  "rdma/rdma_v100": "63"
}
{
  "name": "xxx-a100-xx",
  "rdma/rdma_a100": "63"
}
```

이제 RDMA Shared Device Plugin 을 기반으로 한 설치 방법은 끝났습니다. 바이트댄의 화산 엔진의 일부 제품은 이 방식을 사용합니다.

### 2. GPUDirect 워크로드 설정 시도 (실패)

> [!quote] [GPUDirect 워크로드를 위한 Network Operator 배포](https://docs.nvidia.com/networking/display/kubernetes2501/getting-started-kubernetes.html#network-operator-deployment-for-gpudirect-workloads)

이 섹션은 과정에서 실패한 시도를 기록한 것입니다. RDMA Shared Device Plugin 의 후속 검증에 관심이 있다면 다음 섹션으로 건너뛸 수 있습니다.

RDMA Shared Device Plugin(이하 방법 1) 을 설정하는 과정에서 몇 가지 다른 문제가 발생하여 방법 1 이 작동하지 않는다고 잘못 생각했으며, K8s RDMA Shared Dev Plugin 프로젝트의 토론 섹션에서는 다음과 같은 말이 나왔습니다[^3] (하지만 아래에 반례가 있음에도 불구하고 당시에는 통과시키지 못해, 이미 오래된 것이라고 생각했습니다):

> [!quote] [Adrian Chiris](https://github.com/adrianchiris)
>
> 우리는 프로젝트의 README 를 개선해야 합니다.
>
> 일반적으로 K8s 와 함께 사용하는 방법은 Macvlan 또는 ipoib (또는 어떤 CNI 든) 와 같은 보조 네트워크 CNI 를 사용하는 것입니다.
> **K8s 와 함께 사용하는 일반적인 방법은 Macvlan 또는 ipoib (또는 어떤 CNI 든) 와 같은 보조 네트워크 CNI 를 사용하는 것입니다.**
>
> 우리는 지침과 예제를 업데이트해야 합니다.

이후 문서를 다시 읽어보니 "GPUDirect 워크로드"라는 섹션이 있었습니다 (내 심중의 OS: 다른 설치 방법은 GPU 워크로드가 아니라는 의미인가요?).

방법 1 과 비교하여 이 방법은 DOCA 드라이버, SR-IOV Device Plugin, 보조 네트워크, Multus CNI, 컨테이너 네트워킹 플러그인, IPAM 플러그인을 설치해야 하며, Multus CNI 는 Kubernetes 에서 사용할 수 있는 보조 네트워크 CNI[^4]입니다.

> [!quote]
>
> - **Multus**는 CNI(컨테이너 네트워크 인터페이스) 플러그인으로, 하나의 Kubernetes Pod 에 여러 네트워크 카드를 삽입할 수 있어 더 유연한 네트워크 통신이 가능합니다. Flannel, Calico, Macvlan 등 여러 CNI 플러그인을 지원하며, 다른 네트워크 솔루션과도 잘 통합할 수 있습니다. 일부 경우, Pod 가 여러 다른 네트워크에 동시에 연결되어야 할 수 있으며, Multus 는 이러한 기능을 제공하여 Pod 에 여러 네트워크 인터페이스를 제공하여 다양한 네트워크와 통신할 수 있게 합니다.
> - **Whereabouts**는 IP 주소 관리 도구로, Pod 에 자동으로 IP 주소를 할당하고 IP 주소 충돌을 방지할 수 있습니다. 전통적인 네트워크 구성에서는 각 호스트에 다른 IP 주소 범위를 수동으로 할당해야 했습니다. Whereabouts 는 자동화된 IP 주소 할당 메커니즘을 통해 이 과정을 간소화하여, Kubernetes 클러스터에서 IP 주소를 관리하는 것을 더 효율적이고 신뢰성 있게 만듭니다. 이는 각 Pod 에 고유한 IP 주소를 보장하며, 대규모 클러스터 환경에서도 IP 주소 중복을 효과적으로 피할 수 있도록 합니다.

설치 시, 먼저 Nic Cluster Policy 를 설치합니다:

```yaml
apiVersion: mellanox.com/v1alpha1
kind: NicClusterPolicy
metadata:
  name: nic-cluster-policy
spec:
  ofedDriver:
    image: doca-driver
    repository: nvcr.io/nvidia/mellanox
    version: 25.01-0.6.0.0-0
    forcePrecompiled: false
    imagePullSecrets: []
    terminationGracePeriodSeconds: 300
    startupProbe:
      initialDelaySeconds: 10
      periodSeconds: 20
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 30
    readinessProbe:
      initialDelaySeconds: 10
      periodSeconds: 30
    upgradePolicy:
      autoUpgrade: true
      maxParallelUpgrades: 1
      safeLoad: false
      drain:
        enable: true
        force: true
        podSelector: ""
        timeoutSeconds: 300
        deleteEmptyDir: true
  sriovDevicePlugin:
    image: sriov-network-device-plugin
    repository: ghcr.io/k8snetworkplumbingwg
    version: v3.9.0
    imagePullSecrets: []
    config: |
      {
        "resourceList": [
          {
            "resourcePrefix": "nvidia.com",
            "resourceName": "hostdev",
            "selectors": {
              "vendors": ["15b3"],
              "devices": [],
              "drivers": [],
              "pfNames": [],
              "pciAddresses": [],
              "rootDevices": [],
              "linkTypes": [],
              "isRdma": true
            }
          }
        ]
      }
  secondaryNetwork:
    cniPlugins:
      image: plugins
      repository: ghcr.io/k8snetworkplumbingwg
      version: v1.5.0
      imagePullSecrets: []
    multus:
      image: multus-cni
      repository: ghcr.io/k8snetworkplumbingwg
      version: v4.1.0
      imagePullSecrets: []
    ipamPlugin:
      image: whereabouts
      repository: ghcr.io/k8snetworkplumbingwg
      version: v0.7.0
      imagePullSecrets: []
```

그 후 Where Abouts 의 할당 가능한 IP 를 지정해야 하며, 현재 레이어 2 네트워크에서 사용 중인 IP 와 중복되지 않도록 해야 합니다 (이 점은 Metal LB 가 수행하는 작업과 유사합니다?). 따라서 먼저 스캔하여 사용되지 않은 작은 IP 범위를 선택했습니다.

```yaml
apiVersion: mellanox.com/v1alpha1
kind: HostDeviceNetwork
metadata:
  name: hostdevice-net
spec:
  networkNamespace: "crater-workspace" # 워크로드가 있는 네임스페이스
  resourceName: "hostdev"
  ipam: |
    {
      "type": "whereabouts",
      "datastore": "kubernetes",
      "kubernetes": {
        "kubeconfig": "/etc/cni/net.d/whereabouts.d/whereabouts.kubeconfig"
      },
      "range": "192.168.x.152/27",
      "exclude": ["192.168.x.151/32"],
      "log_file": "/var/log/whereabouts.log",
      "log_level": "info"
    }
```

설치 후, 노드에 `nvidia.com/hostdev` 유형의 리소스가 추가됩니다:

```bash
$ kubectl get nodes -o json | jq -r '.items[] | {
    name: .metadata.name,
    "nvidia.com/hostdev": .status.capacity["nvidia.com/hostdev"]
} | select(.["nvidia.com/hostdev"] != null)'
# 동일한 결과 생략
{
  "name": "xxx-v100-xx",
  "nvidia.com/hostdev": "2"
}
{
  "name": "xxx-a100-xx",
  "nvidia.com/hostdev": "4"
}
```

이 특수한 네트워크를 사용하기 위해 Pod 를 제출할 때 Annotations 도 추가해야 합니다:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: testpod1
  namespace: crater-workspace. # 이전에 지정한 네임스페이스
  annotations:
    k8s.v1.cni.cncf.io/networks: hostdevice-net
spec:
  containers:
    - name: appcntr1
      image: <image>
      imagePullPolicy: IfNotPresent
      securityContext:
        capabilities:
          add: ["IPC_LOCK"] # 이 것은 필수입니다
      command:
        - sh
        - -c
        - sleep inf # 공식 문서의 방식이므로 어떻게 테스트해야 할까요?
      resources:
        requests:
          nvidia.com/hostdev: "1"
          nvidia.com/gpu: "1"
        limits:
          nvidia.com/hostdev: "1"
          nvidia.com/gpu: "1"
```

Pod 에 진입한 후 `ifconfig` 명령어를 실행하면 `net1`이라는 이름의 네트워크 카드가 추가됩니다. 다음으로 어떻게 해야 할까요? Network Operator 의 프로젝트 저장소에서 테스트 파일[^5]을 제공하지만, 명령어도 `sleep inf`입니다.

나는 NCCL 이 네트워크 카드를 지정해야 하는 것 같지만, 이후 RDMA Shared Device Plugin 이 작동해 이후로 이 부분을 깊이 연구하지 않았습니다. 공식적으로 제 혼란을 제기하는 것도 좋은 선택일 수 있습니다.

고정된 자원을 정리하려면 한 터미널에서 `kubectl proxy`를 시작할 수 있습니다:

```shell
$ kubectl proxy
Starting to serve on 127.0.0.1:8001
```

다른 터미널에서 정리 스크립트를 실행하세요 (참고로 `/`은 `~1`로 이스케이프해야 합니다):

```bash
#!/bin/bash

# 적어도 하나의 노드 이름이 제공되었는지 확인합니다
if [ "$#" -lt 1 ]; then
  echo "Usage: $0 <node-name> [<node-name>...]"
  exit 1
fi

# JSON 패치 데이터 준비
PATCH_DATA=$(cat <<EOF
[
  {"op": "remove", "path": "/status/capacity/nvidia.com~1hostdev"}
]
EOF
)

# 제공된 각 노드 이름에 대해 반복합니다
for NODE_NAME in "$@"
do
  # PATCH 요청 실행
  curl --header "Content-Type: application/json-patch+json" \
       --request PATCH \
       --data "$PATCH_DATA" \
       http://127.0.0.1:8001/api/v1/nodes/$NODE_NAME/status

  echo "Patch 요청이 노드 $NODE_NAME에 전송되었습니다"
done
```

노드 이름을 전달하고 정리합니다:

```shell
chmod +x ./patch_node_gpu.sh
./patch_node_gpu.sh node1 node2
```

## RDMA 설치 검증

이 섹션에서는 RDMA Shared Device Plugin 기반 방법으로 RDMA 설치를 어떻게 계속 검증하는지 설명합니다.

### 1. RDMA 를 지원하는 이미지 준비

> [!quote] [이미지가 RDMA 를 지원하는지 확인--머신러닝 플랫폼 - 화산 엔진](https://www.volcengine.com/docs/6459/119595)

V100 기종을 위한 간단한 Dockerfile 은 다음과 같을 수 있습니다:

```dockerfile
FROM xxx/envd:py3.12-ubuntu22.04-8978
USER root

# APT 패키지 설치
RUN apt-get update && apt-get install -y \
	infiniband-diags perftest ibverbs-providers libibumad3 \
	libibverbs1 libnl-3-200 libnl-route-3-200 librdmacm1 && \
    rm -rf /var/lib/apt/lists/*

# Python 의존성은 지정되지 않았습니다
```

여기서 제 기본 이미지에는 일반적으로 사용되는 디버깅 툴킷, Python 및 CUDA 환경이 포함되어 있습니다. 주로 APT 를 통해 InfiniBand 관련 라이브러리를 추가 설치합니다.

이러한 라이브러리를 설치한 후, RDMA 리소스를 요청하지 않고 Pod 를 시작하면 `ibstat`의 내용을 정상적으로 볼 수 있지만, 쓰기 시도와 같은 작업은 InfiniBand 또는 RoCE 장치가 없어 오류를 발생시킵니다.

### 2. 단일 머신에서의 검증 방법

먼저 RDMA 리소스를 요청하는 Pod 를 시작해야 합니다:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: rdma-test-pod-1
spec:
  containers:
  - image: <image>
    name: rdma-test-ctr
    securityContext:
      capabilities:
        add: [ "IPC_LOCK" ]
    resources:
      limits:
	    nvidia.com/v100: "4"
        rdma/rdma_v100: "1"
      requests:
	    nvidia.com/v100: "4"
        rdma/rdma_v100: "1"
    command:
    - sh
    - -c
    - |
      sleep infinity
```

일반적인 GPU 리소스에 대해서는 모델에 따라 이름을 재명명했으며, 관련 자료는 이전의 기사에서 확인할 수 있습니다.

컨테이너가 성공적으로 시작되면 컨테이너에 진입합니다:

1. 다음과 같은 명령어를 입력합니다:

```bash
ib_write_bw -d mlx5_1 &
```

출력 예시는 다음과 같습니다:

```shell
$ ib_write_bw -d mlx5_1 &
[1] 2457716
root@xxx-01:~#
************************************
* Waiting for client to connect... *
************************************
```

2. 동일한 머신에서 다음 명령어를 입력합니다:

```plain
ib_write_bw -d mlx5_1 127.0.0.1 --report_gbits
```

출력 예시는 다음과 같습니다:

```shell
$ ib_write_bw -d mlx5_1 127.0.0.1 --report_gbits
---------------------------------------------------------------------------------------
                    RDMA_Write BW Test
 Dual-port       : OFF          Device         : mlx5_1
---------------------------------------------------------------------------------------
 Number of qps   : 1            Transport type : IB
                    RDMA_Write BW Test
 Connection type : RC           Using SRQ      : OFF
 Dual-port       : OFF          Device         : mlx5_1
 PCIe relax order: ON
 Number of qps   : 1            Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 ibv_wr* API     : ON
 TX depth        : 128
 CQ Moderation   : 1
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Mtu             : 4096[B]
 Link type       : IB
 Link type       : IB
 Max inline data : 0[B]
 Max inline data : 0[B]
 rdma_cm QPs     : OFF
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------
 local address: LID 0xXX QPN 0xXXXX PSN 0xXXXXXX RKey 0xXXXXXX VAddr 0xXXXXXXXXXXXX
 local address: LID 0xXX QPN 0xXXXX PSN 0xXXXXXX RKey 0xXXXXXX VAddr 0xXXXXXXXXXXXX
 remote address: LID 0xXX QPN 0xXXXX PSN 0xXXXXXX RKey 0xXXXXXX VAddr 0xXXXXXXXXXXXX
 remote address: LID 0xXX QPN 0xXXXX PSN 0xXXXXXX RKey 0xXXXXXX VAddr 0xXXXXXXXXXXXX
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[Gb/sec]    BW average[Gb/sec]   MsgRate[Mpps]
Conflicting CPU frequency values detected: 1000.000000 != 3013.932000. CPU Frequency is not max.
 65536      5000             94.72              94.71              0.180640
---------------------------------------------------------------------------------------
 65536      5000             94.72              94.71              0.180640
---------------------------------------------------------------------------------------
[1]+  Done                    ib_write_bw -d mlx5_1
```

V100 RDMA 기종의 경우 대역폭 값 (`BW peak`、`BW average`) 은 `100Gb/s`에 가까워야 하며, A100 RDMA 기종은 `200Gb/s`에 가까워야 합니다. 이 조건을 충족하면 구성이 문제 없습니다. 출력이 없거나 오류가 발생하면 기종에 맞는 환경 구성 부분으로 돌아가 구성 항목을 누락했는지 확인하세요.

### 3. 다중 머신에서의 검증 방법

이전 섹션과 마찬가지로 두 개의 Pod 를 각각 요청하고, 그 중 하나의 Pod 의 Kubernetes 내부 IP 를 기록한 후 명령어를 실행합니다:

```bash
# 서버 명령어
ib_write_bw -a -F --report_gbits -q 2

# 클라이언트 명령어
ib_write_bw -a -F --report_gbits -q 2 <server-pod-default-network-IP>
```

대역폭 값도 `100Gb/s`에 가까워야 하며, 이는 다중 머신 간 연결이 문제 없다는 의미입니다.

### 4. vLLM 다중 머신 분산 추론 실전

마지막으로, 우리는 Volcano Job 을 통해 vLLM 다중 머신 분산 추론 DeepSeek R1 Distill Qwen 32B 모델을 실제로 테스트했습니다. 우리의 모델은 PVC 를 통해 마운트되어 있으며, 이미지는 Envd 를 통해 제작되었습니다. vLLM 은 특별히 제작된 CUDA 12.4 를 설치하므로, 기본 이미지는 CUDA 를 포함할 필요가 없습니다.

```python
# syntax=v1

def build():
    base(image="ubuntu:22.04",dev=True)
    install.python(version="3.12")
    install.apt_packages([
        "openssh-server", "build-essential", "iputils-ping", "net-tools", "htop",
        "infiniband-diags", "perftest", "ibverbs-providers", "libibumad3",
        "libibverbs1", "libnl-3-200", "libnl-route-3-200", "librdmacm1"
    ])
    config.pip_index(url = "https://pypi.tuna.tsinghua.edu.cn/simple")
    install.python_packages(name = ["vllm"])
    config.jupyter()
```

그 후 Volcano Job 을 실행합니다:

```yaml
apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: vllm-rdma-test
  namespace: crater-workspace
spec:
  maxRetry: 3
  minAvailable: 2
  plugins:
    pytorch:
      - --master=master
      - --worker=worker
      - --port=23456
    svc: []
  policies:
    - action: RestartJob
      event: PodEvicted
  queue: default
  schedulerName: volcano
  tasks:
    - maxRetry: 3
      minAvailable: 1
      name: master
      policies:
        - action: CompleteJob
          event: TaskCompleted
        - action: TerminateJob
          event: PodFailed
      replicas: 1
      template:
        spec:
          containers:
            - command:
                - sh
                - -c
                - |-
                  ray start --head --port=6667 --disable-usage-stats;
                  NCCL_DEBUG=TRACE python3 -m vllm.entrypoints.openai.api_server \
                  --model=/models/DeepSeek-R1-Distill-Qwen-32B \
                  --max-model-len 32768 \
                  --tensor-parallel-size 4 \
                  --pipeline-parallel-size 2 \
                  --gpu-memory-utilization 0.90 \
                  --max-num-seqs 128 \
                  --trust-remote-code \
                  --disable-custom-all-reduce \
                  --port 6666 \
                  --dtype=half;
              image: xxx/envd-vllm:0.8.3-cu12.4-rdma-v1
              name: master
              resources:
                limits:
                  nvidia.com/v100: "4"
                  rdma/rdma_v100: "1"
                requests:
                  nvidia.com/v100: "4"
                  rdma/rdma_v100: "1"
              securityContext:
                capabilities:
                  add:
                    - IPC_LOCK
                runAsGroup: 0
                runAsUser: 0
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /dev/shm
                  name: crater-cache
                - mountPath: /models/DeepSeek-R1-Distill-Qwen-32B
                  name: crater-ro-storage
                  readOnly: true
                  subPath: LLM/deepseek/DeepSeek-R1-Distill-Qwen-32B
              workingDir: /models
          restartPolicy: Never
          volumes:
            - emptyDir:
                medium: Memory
              name: crater-cache
            - name: crater-ro-storage
              persistentVolumeClaim:
                claimName: crater-ro-storage
    - maxRetry: 3
      minAvailable: 1
      name: worker
      replicas: 1
      template:
        spec:
          containers:
            - command:
                - sh
                - -c
                - |-
                  ray start --address="$MASTER_ADDR:6667";
                  sleep infinity;
              image: xxx/envd-vllm:0.8.3-cu12.4-rdma-v1
              name: worker
              resources:
                limits:
                  nvidia.com/v100: "4"
                  rdma/rdma_v100: "1"
                requests:
                  nvidia.com/v100: "4"
                  rdma/rdma_v100: "1"
              securityContext:
                capabilities:
                  add:
                    - IPC_LOCK
                runAsGroup: 0
                runAsUser: 0
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /dev/shm
                  name: crater-cache
                - mountPath: /models/DeepSeek-R1-Distill-Qwen-32B
                  name: crater-ro-storage
                  readOnly: true
                  subPath: LLM/deepseek/DeepSeek-R1-Distill-Qwen-32B
              workingDir: /models
          restartPolicy: OnFailure
          volumes:
            - emptyDir:
                medium: Memory
              name: crater-cache
            - name: crater-ro-storage
              persistentVolumeClaim:
                claimName: crater-ro-storage
  ttlSecondsAfterFinished: 259200
```

vLLM 의 분산 추론에 관한 설명[^7]을 참고하여 `NCCL_DEBUG=TRACE`를 활성화했습니다. 로그에서 NCCL 이 Socket 연결 대신 IB 를 사용했음을 확인할 수 있습니다.

추론 과정 중 Kubernetes 가 머신 간 통신 트래픽을 더 이상 감지하지 못하게 되었으며, 이는 배포가 성공했음을 나타냅니다.

## 메모리 잠금 상한 수정

### 0. 문제 설명

다음의 오류들은 모두 메모리 잠금 제한으로 인해 발생합니다.

연결 테스트 중에 다음과 같은 오류가 발생합니다:

```bash
[host1] $ ib_read_bw -q 30

************************************
* Waiting for client to connect... *
************************************
---------------------------------------------------------------------------------------
                    RDMA_Read BW Test
 Dual-port       : OFF          Device         : mlx5_0
 Number of qps   : 30           Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Link type       : IB
 Outstand reads  : 16
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
ethernet_read_keys: Couldn't read remote address
 Unable to read to socket/rdma_cm
Failed to exchange data between server and clients
```

```bash
[host2] $ ib_read_bw -q 30 10.244.46.50
Couldn't allocate MR
failed to create mr
Failed to create MR
 Couldn't create IB resources
```

RDMA 대역폭 테스트 시 작은 데이터(예: 1024 바이트) 전송은 정상이지만, 1M 이상의 데이터 전송은 실패합니다. 구체적인 오류 메시지는 위와 같습니다. 자세한 내용은 [Issue #339](https://github.com/raids-lab/crater/issues/339)를 참조하십시오.

`ulimit -l`을 사용하여 직접 제한을 확인하면 시스템 기본 메모리 잠금 상한인 64KB 가 나타납니다.

이때 컨테이너 내부에서 `ulimit -l unlimited`를 사용하거나 `/etc/security/limits.conf`를 수정해도 메모리 잠금 상한을 정상적으로 변경할 수 없습니다.

### 1. 문제 분석

RDMA 의 핵심은 하드웨어(네트워크 카드 HCA)가 CPU 를 우회하여 원격 메모리에 직접 액세스할 수 있도록 하는 것입니다. 일반적으로 운영체제는 메모리를 최적화하기 위해 언제든지 "페이징"을 수행하거나 데이터를 이동시켜 가상 주소에 대응하는 물리 주소를 변경할 수 있습니다. 네트워크 카드가 데이터를 전송하는 동안 커널이 해당 메모리 페이지를 스왑 아웃하거나 이동시키면 전송 중단이나 시스템 오류가 발생합니다.

따라서 주소를 완전히 고정하기 위해 RDMA 는 전송 전에 "메모리 등록"(Memory Registration, MR)을 수행해야 합니다. 이 작업은 커널 수준에서 특정 가상 메모리 페이지를 물리 메모리에 "잠금"(Lock)하여 커널이 이를 이동시키거나 디스크로 스왑하는 것을 금지합니다.

Crater 는 이미 작업에 `CAP_IPC_LOCK`을 설정하여 메모리 잠금 작업을 수행할 수 있도록 허용했지만, 잠글 수 있는 양에 대한 제한은 수정하지 않았습니다. 또한 컨테이너에 `CAP_SYS_RESOURCE` 특권이 없으므로 컨테이너 내부 작업으로는 이 상한을 변경할 수 없습니다.

현재 Kubernetes 공식은 Pod Spec 에서 `ulimit`을 직접 설정하는 기능을 제공하지 않습니다(자세한 내용은 [Issue #3595](https://github.com/kubernetes/kubernetes/issues/3595) 참조). 따라서 컨테이너 런타임 차원에서 접근해야 합니다.

> 기대해 볼 만한 점은, Kubernetes 커뮤니티가 v1.36 사이클에서 Pod 수준의 ulimit 설정에 대한 기본 지원 논의를 공식적으로 시작했다는 것입니다(자세한 내용은 [KEP-5758](https://github.com/kubernetes/enhancements/pull/5762) 참조).

`dockerd` 런타임에는 해당하는 구성 항목인 `default-ulimits`가 있어 노드 수준에서 이 제한을 비교적 쉽게 구성할 수 있습니다. 자세한 내용은 [구성 파일 설명](https://docs.docker.com/reference/cli/dockerd/#daemon-configuration-file) 및 [리소스 제한 가이드](https://docs.docker.com/engine/containers/resource_constraints/#set-default-ulimits-for-a-container)를 참조하십시오.

그러나 현재 클러스터에서 사용하는 것은 `containerd`이며, `dockerd`와 같은 구성 항목을 제공하지 않습니다. 자세한 내용은 [구성 파일 설명](https://github.com/containerd/containerd/blob/main/docs/cri/config.md)을 참조하십시오. 반면 개발자들은 [Issue #3150](https://github.com/containerd/containerd/issues/3150)에서 데몬 수준의 구성을 제공하는 것을 명확히 거부했습니다. 따라서 이 문제를 해결하기 위해 다른 방법을 찾아야 합니다.

> 또한 시도 결과, 노드에서 직접 `/etc/security/limits.conf`를 수정하여 제한을 해제하거나, 컨테이너 런타임 데몬에 대해서만 `LimitMEMLOCK=infinity`를 설정해도 Pod 내부의 제한을 해제할 수 없습니다. 그 근본 원인은 컨테이너 실행기인 `runc`가 OCI 사양 블루프린트의 정의를 엄격히 따르며 시작 시 컨테이너에 대해 `setrlimit` 시스템 호출을 수행하기 때문인 것으로 보입니다. 이로 인해 데몬 자체의 권한 상한과 관계없이 컨테이너의 제한이 블루프린트 내부의 기본값(예: 64KB)으로 강제 덮어쓰기(대개 하향 조정)됩니다.

### 2. 해결 방법

이 해결 방법의 핵심은 **OCI Runtime Specification (OCI 런타임 사양)**을 수정하는 데 있습니다. `containerd` 문맥에서 `base_runtime_spec` 파라미터로 지정된 JSON 파일은 컨테이너의 **기본 사양 템플릿**으로 간주됩니다. 이것이 컨테이너의 최종적이고 권위 있는 리소스 경계(예: `memlock` 제한)의 정보원입니다(자세한 내용은 [OCI 구성 사양](https://github.com/opencontainers/runtime-spec/blob/main/config.md#posix-process) 참조). 하부 OCI 런타임(예: `runc`)은 블루프린트 정의에 따라 `setrlimit` 시스템 호출을 통해 컨테이너 프로세스의 리소스 제한을 초기화합니다.

#### 기존 구성 내보내기 및 수정

`containerd`는 이 파라미터를 시스템 기본 구성과 자동으로 병합(Merge)하는 기능을 지원하지 않고 완전히 대체(Replace)하는 전략을 사용하므로, 먼저 현재 시스템의 전체 정의가 포함된 구성 템플릿을 내보낸 후 미세 조정을 수행해야 합니다. 노드에서 다음 명령을 실행하십시오:

```shell
ctr oci spec > /etc/containerd/rdma-spec.json
vim /etc/containerd/rdma-spec.json
```

구성 파일의 다음 부분을 수정하십시오 (`rlimits` 배열에 `RLIMIT_MEMLOCK` 추가):

```json
        "rlimits": [
            {
                "type": "RLIMIT_NOFILE",
                "hard": 1024,
                "soft": 1024
            },
            {
                "type": "RLIMIT_MEMLOCK",
                "hard": 18446744073709551615,
                "soft": 18446744073709551615
            }
        ],
```

#### 수정된 구성 참조

`containerd` 구성을 수정하십시오.

```toml
      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]

        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
          # 위에서 생성한 JSON 템플릿의 절대 경로를 가리키도록 수정
          base_runtime_spec = "/etc/containerd/rdma-spec.json"
          cni_conf_dir = ""
          cni_max_conf_num = 0
          container_annotations = []
          pod_annotations = []
          privileged_without_host_devices = false
          privileged_without_host_devices_all_devices_allowed = false
          runtime_engine = ""
          runtime_path = ""
          runtime_root = ""
          runtime_type = "io.containerd.runc.v2"
          sandbox_mode = "podsandbox"
          snapshotter = ""
```

구체적인 상황에 맞게 수정해야 합니다. 목표는 해당 Pod 가 해당 구성을 정상적으로 적용할 수 있도록 하는 것입니다.

<Callout type="warn">
컨테이너 런타임 구성을 수정하고 서비스를 재시작한 후에도 **이미 실행 중인 Pod 에는 영향을 미치지 않습니다**. 기존 Pod 를 수동으로 삭제해야 Kubernetes 가 다시 스케줄링을 수행하고 `containerd`가 새로운 OCI 블루프린트를 사용하여 초기화하도록 트리거하여 구성이 실제로 적용됩니다.
</Callout>

#### containerd 자체 제한 해제 (선택 사항)

```shell
EDITOR=vim systemctl edit containerd
```

데몬 구성에 다음 내용을 추가하십시오:

```toml
[Service]
LimitMEMLOCK=infinity
```

이후 `systemctl restart containerd`를 사용하여 서비스를 재시작하십시오.

실제 테스트 결과, `containerd`가 `CAP_SYS_RESOURCE` 특권을 가지고 있어 OCI 블루프린트 수정만으로도 효과가 있는 것으로 나타났으나, 데몬 자체의 견고성을 보장하기 위해 이 항목을 보완하는 것이 프로덕션 환경에서의 모범 사례로 권장됩니다.

#### 테스트

이제 Pod 내부의 메모리 잠금 상한이 해제되었을 것입니다. RDMA 대역폭 테스트 명령을 다시 실행하면 마스터와 워커에서 각각 다음과 같은 출력이 표시됩니다.

**Master:**

```bash
root@pyt-liuyizhou-260206-2a3fe-master-0:/# ib_write_bw -s 1M -d mlx5_0 -F
************************************
* Waiting for client to connect... *
************************************
---------------------------------------------------------------------------------------
                    RDMA_Write BW Test
 Dual-port       : OFF          Device         : mlx5_0
 Number of qps   : 1            Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 TX depth        : 128
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Link type       : IB
 Max inline data : 0[B]
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
 local address: LID 0x2c QPN 0x0087 PSN 0xcc6a4c RKey 0x1fcc bd VAddr 0x037f67d3b5030
 remote address: LID 0x2c QPN 0x0088 PSN 0x6dc93a RKey 0x1fcf be VAddr 0x037f026db4030
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]
 1048576    5000             11133.60            11129.09           0.011123
---------------------------------------------------------------------------------------
```

**Worker:**

```bash
root@pyt-liuyizhou-260206-2a3fe-worker-0:/# ib_write_bw -s 1M -d mlx5_0 -F 10.244.44.139
---------------------------------------------------------------------------------------
                    RDMA_Write BW Test
 Dual-port       : OFF          Device         : mlx5_0
 Number of qps   : 1            Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 TX depth        : 128
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Link type       : IB
 Max inline data : 0[B]
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
 local address: LID 0x2c QPN 0x0088 PSN 0x6dc93a RKey 0x1fcf be VAddr 0x037f026db4030
 remote address: LID 0x2c QPN 0x0087 PSN 0xcc6a4c RKey 0x1fcc bd VAddr 0x037f67d3b5030
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]
 1048576    5000             11133.60            11129.09           0.011123
---------------------------------------------------------------------------------------

root@pyt-liuyizhou-260206-2a3fe-worker-0:/# ulimit -l
unlimited
```

Pod 내부의 메모리 잠금 상한이 해제되어 큰 대역폭에서도 RDMA 통신이 정상적으로 이루어지는 것을 확인할 수 있습니다.

## 문제 기록

### 1. vLLM 시작 시 `Segmentation fault` 오류 발생

로그를 보면 IB 장치가 정상적으로 인식되었음에도 세그멘테이션 오류가 발생합니다.

```bash
[장치명]-master-0:528:528 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[장치명]-master-0:528:528 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[장치명]-master-0:528:528 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->4
    self.device_communicator = device_comm_cls(
[장치명]-master-0:528:528 [0] NCCL INFO P2P Chunksize set to 131072
[장치명]-master-0:528:528 [0] NCCL INFO Channel 00/0 : 7[3] -> 0[0] [receive] via NET/IB/0
[장치명]-master-0:528:528 [0] NCCL INFO Channel 01/0 : 7[3] -> 0[0] [receive] via NET/IB/0
[장치명]-master-0:528:528 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
[장치명]-master-0:528:528 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
[장치명]-master-0:528:5379 [0] misc/socket.cc:50 NCCL WARN socketProgress: Connection closed by remote peer [장치명]-worker-0.[호스트명].svc.cluster.local<35396>
[장치명]-master-0:528:5379 [0] NCCL INFO misc/socket.cc:752 -> 6
[장치명]-master-0:528:5379 [0] NCCL INFO transport/net_ib.cc:1207 -> 6
[장치명]-master-0:528:5379 [0] NCCL INFO transport/net.cc:837 -> 6
[장치명]-master-0:528:528 [0] NCCL INFO transport/net.cc:405 -> 6
[장치명]-master-0:528:528 [0] NCCL INFO transport.cc:183 -> 6
                               ^^^^^^^^^^^^^^^^
[장치명]-master-0:528:528 [0] NCCL INFO init.cc:1263 -> 6
[장치명]-master-0:528:528 [0] NCCL INFO init.cc:1548 -> 6
[장치명]-master-0:528:528 [0] NCCL INFO init.cc:1799 -> 6
  File "/opt/conda/envs/envd/lib/python3.12/site-packages/vllm/distributed/device_communicators/cuda_communicator.py", line 39, in __init__
[장치명]-master-0:528:5379 [0] misc/socket.cc:50 NCCL WARN socketProgress: Connection closed by remote peer [장치명]-worker-0.[호스트명].svc.cluster.local<52144>
    self.pynccl_comm = PyNcclCommunicator(
                       ^^^^^^^^^^^^^^^^^^^
[장치명]-master-0:528:5379 [0] NCCL INFO misc/socket.cc:752 -> 6
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[장치명]-master-0:528:5379 [0] NCCL INFO transport/net_ib.cc:1207 -> 6
  File "/opt/conda/envs/envd/lib/python3.12/site-packages/vllm/distributed/device_communicators/pynccl.py", line 99, in __init__
    self.comm: ncclComm_t = self.nccl.ncclCommInitRank(
  File "/opt/conda/envs/envd/lib/python3.12/site-packages/vllm/distributed/device_communicators/pynccl_wrapper.py", line 277, in ncclCommInitRank
    self.NCCL_CHECK(self._funcs["ncclCommInitRank"](ctypes.byref(comm),
  File "/opt/conda/envs/envd/lib/python3.12/site-packages/vllm/distributed/device_communicators/pynccl_wrapper.py", line 256, in NCCL_CHECK
    raise RuntimeError(f"NCCL error: {error_str}")
RuntimeError: NCCL error: unhandled system error (run with NCCL_DEBUG=INFO for details)
[장치명]-master-0:528:5379 [0] NCCL INFO transport/net.cc:837 -> 6
[장치명]-master-0:528:528 [0] NCCL INFO init.cc:1837 -> 6
*** SIGSEGV received at time=1745072123 on cpu 70 ***
PC: @     0x7ff94e269506  (unknown)  ncclProxyServiceUDS()
    @     0x7ffa0c242520       3384  (unknown)
    @ ... and at least 1 more frames
[2025-04-19 14:15:23,982 E 528 5383] logging.cc:484: *** SIGSEGV received at time=1745072123 on cpu 70 ***
[2025-04-19 14:15:23,982 E 528 5383] logging.cc:484: PC: @     0x7ff94e269506  (unknown)  ncclProxyServiceUDS()
[2025-04-19 14:15:23,983 E 528 5383] logging.cc:484:     @     0x7ffa0c242520       3384  (unknown)
[2025-04-19 14:15:23,983 E 528 5383] logging.cc:484:     @ ... and at least 1 more frames
Fatal Python error: Segmentation fault
```

이전에 Pod 의 보안 컨텍스트에 `IPC_LOCK`을 추가해야 한다고 말씀드린 것을 기억하시나요? 이를 추가하지 않으면 위와 같은 문제가 발생합니다.

### 2. A100 기종에서 다중 머신 추론 실패

먼저 A100 기종에서 단일 머신 검증을 수행했습니다. Up 상태인 네트워크 카드를 사용하면 문제없는 것으로 보입니다:

```bash
$ ib_write_bw -d mlx5_1 &
[1] 1501

************************************
* Waiting for client to connect... *
************************************


$ ib_write_bw -d mlx5_1 127.0.0.1 --report_gbits
---------------------------------------------------------------------------------------
                    RDMA_Write BW Test
 Dual-port       : OFF          Device         : mlx5_1
 Number of qps   : 1            Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Link type       : IB
 Max inline data : 0[B]
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------
                    RDMA_Write BW Test
 Dual-port       : OFF          Device         : mlx5_1
 Number of qps   : 1            Transport type : IB
 Connection type : RC           Using SRQ      : OFF
 PCIe relax order: ON
 ibv_wr* API     : ON
 TX depth        : 128
 CQ Moderation   : 1
 Mtu             : 4096[B]
 Link type       : IB
 Max inline data : 0[B]
 rdma_cm QPs     : OFF
 Data ex. method : Ethernet
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]
---------------------------------------------------------------------------------------
 #bytes     #iterations    BW peak[Gb/sec]    BW average[Gb/sec]   MsgRate[Mpps]
Conflicting CPU frequency values detected: 863.109000 != 2300.000000. CPU Frequency is not max.
 65536      5000             183.66             183.61             0.350214
---------------------------------------------------------------------------------------
 65536      5000             183.66             183.61             0.350214
---------------------------------------------------------------------------------------

$ ib_write_bw -d mlx5_0 &
[1] 1618

Port number 1 state is Down
 Couldn't set the link layer
 Couldn't get context for the device

$ ib_write_bw -d mlx5_0 127.0.0.1 --report_gbits
 Port number 1 state is Down
 Couldn't set the link layer
 Couldn't get context for the device

$ ibstat
CA 'mlx5_0'
        CA type: MT4123
        Port 1:
                State: Down
                Physical state: Disabled
                Rate: 10
                Base lid: 65535
                LMC: 0
                SM lid: 0
                Link layer: InfiniBand
CA 'mlx5_1'
        CA type: MT4123
        Port 1:
                State: Active
                Physical state: LinkUp
                Rate: 200
                Base lid: 3
                LMC: 0
                SM lid: 1
                Link layer: InfiniBand
CA 'mlx5_bond_0'
        CA type: MT4117
        Port 1:
                State: Active
                Physical state: LinkUp
                Rate: 10
                Link layer: Ethernet

$ ib_write_bw -d mlx5_bond_0 &
IB device mlx5_bond_0 not found
 Unable to find the Infiniband/RoCE device
```

하지만 vLLM 실행 시 오류가 발생합니다. 조사 결과, 이 문제는 vLLM V1 및 Ray[^8]와 관련된 문제로 확인되었으며 IB 와는 무관합니다. 마침 vLLM 다중 머신 분산 추론 코드가 있어 테스트에 사용했지만, 외부 간섭 요인을 피하기 위해 NCCL Test 등을 사용하는 것이 좋습니다.

## 요약

이상으로 로컬 Kubernetes 클러스터에서 RDMA 연결을 구축하는 과정을 기록했습니다. 현재 관련 문서의 부족과 문제 영역의 방대함이 이 분야 학습의 주요 장애물입니다. 확실히 탄탄한 컴퓨터 기초 지식이 요구됩니다.

[^1]: [2 个 RoCE 网卡 Bond 聚合，实现带宽 X2-云社区 - 华为云](https://bbs.huaweicloud.com/blogs/412088)
[^2]: [RDG for Accelerated K8s Cluster over NVIDIA DGX A100 Servers and 200Gbps Ethernet Network Fabric](https://docs.nvidia.com/networking/display/public/sol/rdg+for+accelerated+k8s+cluster+over+nvidia+dgx+a100+servers+and+200gbps+ethernet+network+fabric)
[^3]: [Enhance documentaitons · Issue #54 · Mellanox/k8s-rdma-shared-dev-plugin](https://github.com/Mellanox/k8s-rdma-shared-dev-plugin/issues/54)
[^4]: [Multus-CNI 与 whereabouts 的简单运用 - 剑轩的专栏 - TNBLOG](https://www.tnblog.net/aojiancc2/article/details/7929)
[^5]: [hostdevice-network-pod1.yml](https://github.com/Mellanox/network-operator/tree/master/example)
[^6]: [理想与现实  - Infiniband 和以太网的抉择   -  雪球](https://xueqiu.com/2448317325/292453176?md5__1038=eqAxgDyDuD0jQGXBDrDcQ8FKiIwx8iD)
[^7]: [Distributed Inference and Serving](https://docs.vllm.ai/en/stable/serving/distributed_serving.html)
[^8]: [[Bug]: 0.8.0(V1) Ray cannot find model pyarrow and pandas](https://github.com/vllm-project/vllm/issues/15100)
